"""Long Short Term Memory Network Classifier python module

website references:
https://www.kaggle.com/ternaryrealm/lstm-time-series-explorations-with-keras"""

import time
import itertools
import os
from os import listdir
from os.path import isfile, join

from numpy import genfromtxt
import numpy as np
from keras.models import Sequential
from keras.layers import LSTM, Dense
from keras.wrappers.scikit_learn import KerasRegressor
from keras.layers.convolutional import Conv1D
from keras.layers.convolutional import MaxPooling1D
from keras.utils import to_categorical
from sklearn.ensemble import AdaBoostClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import cross_val_score
import matplotlib.pyplot as plt

# fix random seed for reproducibility
# seed = 7
# np.random.seed(seed)

# Disable tensorflow warning messages
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# Data Parameters
NUM_CLASS = 4  # Change to two for Healthy vs Diseased binary classification
NUM_FEATURES = 20
NUM_TIME_SERIES = 90000
NUM_TS_CROP = 20000  # time series data cropped by NUM_TS_CROP/2 on start and end
NUM_SKIP_SAMP = 5 # number of time series samples to skip over (after crop)

# Split Parameters
NUM_K_SPLIT = 5  # number k fold to split into training and test
VAL_SPLIT = 0.3  # validation set split from split training set (randomized for each k fold cross validation)

# Run Parameters
NUM_LSTM_CELLS = 50
NUM_EPOCH = 20
BATCH_SIZE = 500

if NUM_CLASS == 4:
    LABEL_CTRL = 0
    LABEL_ALS = 1
    LABEL_HUNT = 2
    LABEL_PARK = 3
    n_outputs = 4
    class_names = ['Control', 'ALS', 'Hunting', 'Parkingson']
else:
    LABEL_CTRL = 0
    LABEL_ALS = 1
    LABEL_HUNT = 1
    LABEL_PARK = 1
    n_outputs = 1
    class_names = ['Healthy', 'Diseased']


def load_data(folder):
    file_list = [f for f in listdir(folder) if isfile(join(folder, f))]

    # Labels for time series data
    y = []

    X_file_list = []

    print('Loading: label | file')
    for file_name in file_list:
        if 'als' in file_name:
            y.append(LABEL_ALS)
            X_file_list.append(file_name)
            print(LABEL_ALS, end='')
        elif 'control' in file_name:
            y.append(LABEL_CTRL)
            X_file_list.append(file_name)
            print(LABEL_CTRL, end='')
        elif 'hunt' in file_name:
            y.append(LABEL_HUNT)
            X_file_list.append(file_name)
            print(LABEL_HUNT, end='')
        elif 'park' in file_name:
            y.append(LABEL_PARK)
            X_file_list.append(file_name)
            print(LABEL_PARK, end='')
        else:
            print('~', end='')
        print(' |', file_name)

    # Time series data, (only using leg 0 for the time being)
    X = np.empty([len(y), NUM_TIME_SERIES, NUM_FEATURES], float)

    for f_i in range(len(X_file_list)):
        if any(x in file_list[f_i] for x in ['als', 'control', 'hunt', 'park']):
            data = genfromtxt(folder + file_list[f_i], delimiter=',', dtype=float)
            X[f_i] = data

    # Crop time series data
    X_crop = X[:, int(NUM_TS_CROP / 2):int(NUM_TIME_SERIES - NUM_TS_CROP / 2), :]

    # Downsample time series data
    X_half = X_crop[:, 0::NUM_SKIP_SAMP, :]

    # Convert nan to 0
    for s in range(X_half.shape[0]):
        for t in range(X_half.shape[1]):
            for f in range(X_half.shape[2]):
                if np.isnan(X_half[s, t, f]):
                    X_half[s, t, f] = 0

    # Assert no Inf or nan data
    assert not np.isnan(X_half.any())

    X_final = X_half

    return X_final, np.asarray(y)


def baseline_model(num_lstm_cells=NUM_LSTM_CELLS, num_time_series=(NUM_TIME_SERIES-NUM_TS_CROP)):
    # The model will be designed in the following manner:
    # LSTM -> 1 sigmoid Dense Layer

    # initialize a sequential keras model
    model = Sequential()

    # Input:
    model.add(Dense(NUM_FEATURES, activation='sigmoid',
                    input_shape=(num_time_series, NUM_FEATURES)))
    # model.add(Dense(int(NUM_FEATURES/2), activation='relu'))
    # model.add(Dense(NUM_CLASS, activation='relu'))
    # model.add(Dense(int(NUM_FEATURES/2), activation='relu'))
    # model.add(Dense(NUM_FEATURES, activation='sigmoid'))

    # CNN 1D
    # model.add(Conv1D(filters=32,
    #                  kernel_size=3,
    #                  padding='same',
    #                  activation='relu',
    #                  input_shape=(num_time_series, NUM_FEATURES)))
    #
    # # Pooling
    # model.add(MaxPooling1D(pool_size=2))

    # LSTM Master Layer
    model.add(LSTM(num_lstm_cells,
                   dropout=0.1,
                   recurrent_dropout=0.1,
                   return_sequences=True
                   # input_shape=(num_time_series, NUM_FEATURES
                   )
              )

    # LSTM Support Layer
    model.add(LSTM(NUM_CLASS))

    # Output: Dense Layer Classifier
    # compile and fit our model
    if NUM_CLASS == 2:
        model.add(Dense(n_outputs, activation='sigmoid'))
        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

    elif NUM_CLASS == 4:
        model.add(Dense(n_outputs, activation='softmax'))
        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

    return model


def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.tight_layout()


# Run the following script using the following command via "python -m LSTMN.py"
if __name__ == "__main__":
    # Time Start
    start_time = time.time()

    project_folder = '/media/alexanderfernandes/6686E8B186E882C3/Users/alexanderfernandes/Code/BIOM5405-ClassProject/'
    # project_folder = 'D:/Users/Documents/School/Grad/BIOM5405/project/BIOM5405-ClassProject/'

    X_total, y_total = load_data(project_folder + 'data/')

    print('X_total =', X_total.shape)
    print('y_total = ', y_total.tolist())

    n_timesteps = X_total.shape[1]
    n_features = X_total.shape[2]

    print("Number Classes:", n_outputs)
    print("Cropped Time Series Length:", n_timesteps)
    print("Number Features:", NUM_FEATURES)

    # define 5-fold cross validation test harness
    kfold = StratifiedKFold(n_splits=NUM_K_SPLIT, shuffle=True)
    cvscores = []
    cm_sum = None

    # Bagging
    nbags = 5

    fold_number = 1 # Print logging counter
    for train_index, test_index in kfold.split(X_total, y_total):

        print("CV Fold %d/%d" % (fold_number, NUM_K_SPLIT))
        fold_number += 1

        X_train, X_test = X_total[train_index], X_total[test_index]
        y_train, y_test = y_total[train_index], y_total[test_index]

        if NUM_CLASS == 4:
            y_train = to_categorical(y_train, num_classes=n_outputs)
            y_test = to_categorical(y_test, num_classes=n_outputs)

        print("TRAIN/VAL:", len(train_index), train_index.tolist())
        print("TEST:", len(test_index), test_index.tolist())

        # Split validation set from the training set
        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=VAL_SPLIT)

        # Regular Model
        model = baseline_model()
        model.fit(X_train, y_train,
                  validation_data=(X_val, y_val),
                  epochs=NUM_EPOCH,
                  batch_size=BATCH_SIZE,
                  verbose=2)
        scores = model.evaluate(X_test, y_test, verbose=2)
        print("%s: %.2f%%" % (model.metrics_names[1], scores[1] * 100))
        cvscores.append(scores)
        y_pred = model.predict(X_test, batch_size=BATCH_SIZE)

        print("y_test:", y_test)
        print("y_pred:", y_pred)

        # classify output predictions
        if NUM_CLASS == 2:
            y_pred = (y_pred > 0.5)
        elif NUM_CLASS == 4:
            y_ohe = y_pred
            y_pred = []
            for y in y_ohe:
                mx = 0
                mx_i = None
                for i in range(4):
                    if y[i] > mx:
                        mx_i = i
                        mx = y[i]
                y_pred.append(mx_i)
            y_ohe = y_test
            y_test = []
            for y in y_ohe:
                mx = 0
                mx_i = None
                for i in range(4):
                    if y[i] > mx:
                        mx_i = i
                        mx = y[i]
                y_test.append(mx_i)

        print("y_test:", y_test)
        print("y_pred:", y_pred)

        # confusion matrix
        if cm_sum is None:
            cm_sum = confusion_matrix(y_test, y_pred)
        else:
            cm_sum += confusion_matrix(y_test, y_pred)

    print("%.2f%% (+/- %.2f%%)" % (np.mean(cvscores), np.std(cvscores)))

    # Plot non-normalized confusion matrix
    plt.figure()
    plot_confusion_matrix(cm_sum, classes=class_names, title='Confusion matrix, without normalization')

    # Time End
    elapsed_time = time.time()
    hours, rem = divmod(elapsed_time - start_time, 3600)
    minutes, seconds = divmod(rem, 60)
    print("Elapsed Time: {:0>2}:{:0>2}:{:05.2f}".format(int(hours), int(minutes), seconds))

    plt.show()



"""Meta Learning Strategy"""
from keras import Model
from keras.layers import Dense
from keras.layers.merge import concatenate
from keras.utils import to_categorical
from scipy.stats import mode
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import StratifiedKFold, train_test_split

import os

from sklearn.utils import resample

import python.src.LSTMN as lstmn
import time
import numpy as np
import matplotlib.pyplot as plt
import random

# Disable tensorflow warning messages
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# Run the following script using the following command via "python -m ML.py"
if __name__ == "__main__":
    # Time Start
    start_time = time.time()

    project_folder = '/media/alexanderfernandes/6686E8B186E882C3/Users/alexanderfernandes/Code/BIOM5405-ClassProject/'
    # project_folder = 'D:/Users/Documents/School/Grad/BIOM5405/project/BIOM5405-ClassProject/'

    # LSTMN Parameters:
    lstmn.NUM_CLASS = 2  # Change to two for Healthy vs Diseased binary classification
    lstmn.NUM_EPOCH = 20
    lstmn.BATCH_SIZE = 500

    # Meta Learning Classifier Parameters
    tin_lstm_units = 2
    sml_lstm_units = 10
    med_lstm_units = 25
    lrg_lstm_units = 50
    hug_lstm_units = 100

    if lstmn.NUM_CLASS == 4:
        lstmn.LABEL_CTRL = 0
        lstmn.LABEL_ALS = 1
        lstmn.LABEL_HUNT = 2
        lstmn.LABEL_PARK = 3
        lstmn.n_outputs = 4
        class_names = ['Control', 'ALS', 'Hunting', 'Parkingson']
    else:
        lstmn.LABEL_CTRL = 0
        lstmn.LABEL_ALS = 1
        lstmn.LABEL_HUNT = 1
        lstmn.LABEL_PARK = 1
        lstmn.n_outputs = 1
        class_names = ['Healthy', 'Diseased']

    # Load Data
    X_total, y_total = lstmn.load_data(project_folder + 'data/')

    print('X_total =', X_total.shape)
    print('y_total = ', y_total.tolist())

    n_timesteps = X_total.shape[1]
    n_features = X_total.shape[2]
    if lstmn.LABEL_ALS == lstmn.LABEL_HUNT == lstmn.LABEL_PARK:
        # Health vs Diseased
        n_outputs = 1
    else:
        # Classify Disease Type
        n_outputs = 4

    print("Number Classes:", n_outputs)
    print("Cropped Time Series Length:", n_timesteps)
    print("Number Features:", lstmn.NUM_FEATURES)

    # # Time series split
    # num_classifiers = 5
    # n_timesteps = int(n_timesteps / num_classifiers)

    # define 5-fold cross validation test harness
    kfold = StratifiedKFold(n_splits=lstmn.NUM_K_SPLIT, shuffle=True)
    cvscores = []
    cm_sum = None

    fold_number = 1
    for train_index, test_index in kfold.split(X_total, y_total):

        print("\nCV Fold %d/%d" % (fold_number, lstmn.NUM_K_SPLIT))
        fold_number += 1

        X_train, X_test = X_total[train_index], X_total[test_index]
        y_train, y_test = y_total[train_index], y_total[test_index]

        if lstmn.NUM_CLASS == 4:
            y_train = to_categorical(y_train, num_classes=n_outputs)
            y_test = to_categorical(y_test, num_classes=n_outputs)

        print("TRAIN/VAL:", len(train_index), train_index.tolist())
        print("TEST:", len(test_index), test_index.tolist())

        # Split Data from time series axis into equal portions
        # X_1_train = np.empty([X_train.shape[0], n_timesteps, lstmn.NUM_FEATURES], float)
        # X_2_train = X_1_train
        # X_3_train = X_1_train
        # X_4_train = X_1_train
        # X_5_train = X_1_train
        #
        # X_1_test = np.empty([X_test.shape[0], n_timesteps, lstmn.NUM_FEATURES], float)
        # X_2_test = X_1_test
        # X_3_test = X_1_test
        # X_4_test = X_1_test
        # X_5_test = X_1_test
        #
        # Split accross time
        # for sub in range(X_train.shape[0]):
        #     X_1_train[sub, :, :] = X_train[sub, 0*n_timesteps:1*n_timesteps, :]
        #     X_2_train[sub, :, :] = X_train[sub, 1*n_timesteps:2*n_timesteps, :]
        #     X_3_train[sub, :, :] = X_train[sub, 2*n_timesteps:3*n_timesteps, :]
        #     X_4_train[sub, :, :] = X_train[sub, 3*n_timesteps:4*n_timesteps, :]
        #     X_5_train[sub, :, :] = X_train[sub, 4*n_timesteps:5*n_timesteps, :]
        # for sub in range(X_test.shape[0]):
        #     X_1_test[sub, :, :] = X_test[sub, 0*n_timesteps:1*n_timesteps, :]
        #     X_2_test[sub, :, :] = X_test[sub, 1*n_timesteps:2*n_timesteps, :]
        #     X_3_test[sub, :, :] = X_test[sub, 2*n_timesteps:3*n_timesteps, :]
        #     X_4_test[sub, :, :] = X_test[sub, 3*n_timesteps:4*n_timesteps, :]
        #     X_5_test[sub, :, :] = X_test[sub, 4*n_timesteps:5*n_timesteps, :]
        #
        # y_1_train = y_train
        # y_2_train = y_train
        # y_3_train = y_train
        # y_4_train = y_train
        # y_5_train = y_train


        # Bootstrapping
        nbootstrap = X_train.shape[0] * 3
        X_1_seed = np.random.choice(X_train.shape[0], nbootstrap)
        X_2_seed = np.random.choice(X_train.shape[0], nbootstrap)
        X_3_seed = np.random.choice(X_train.shape[0], nbootstrap)
        X_4_seed = np.random.choice(X_train.shape[0], nbootstrap)
        X_5_seed = np.random.choice(X_train.shape[0], nbootstrap)

        X_1_train = np.empty([nbootstrap, n_timesteps, lstmn.NUM_FEATURES], float)
        X_2_train = X_1_train
        X_3_train = X_1_train
        X_4_train = X_1_train
        X_5_train = X_1_train

        X_1_test = X_test
        X_2_test = X_test
        X_3_test = X_test
        X_4_test = X_test
        X_5_test = X_test

        if lstmn.NUM_CLASS == 4:
            y_1_train = np.empty([nbootstrap, 4])
        elif lstmn.NUM_CLASS == 2:
            y_1_train = np.empty([nbootstrap, 1])

        y_2_train = y_1_train
        y_3_train = y_1_train
        y_4_train = y_1_train
        y_5_train = y_1_train

        for b in range(nbootstrap):
            X_1_train[b, :, :] = X_train[X_1_seed[b], :, :]
            X_2_train[b, :, :] = X_train[X_2_seed[b], :, :]
            X_3_train[b, :, :] = X_train[X_3_seed[b], :, :]
            X_4_train[b, :, :] = X_train[X_4_seed[b], :, :]
            X_5_train[b, :, :] = X_train[X_5_seed[b], :, :]
            y_1_train[b] = y_train[X_1_seed[b]]
            y_2_train[b] = y_train[X_2_seed[b]]
            y_3_train[b] = y_train[X_3_seed[b]]
            y_4_train[b] = y_train[X_4_seed[b]]
            y_5_train[b] = y_train[X_5_seed[b]]

        print("Bootstrap Sample Set:")
        print("Tiny   | train:",  X_1_train.shape, "test:", X_1_test.shape)
        print("Small  | train:",  X_2_train.shape, "test:", X_2_test.shape)
        print("Medium | train:",  X_3_train.shape, "test:", X_3_test.shape)
        print("Large  | train:",  X_4_train.shape, "test:", X_4_test.shape)
        print("Huge   | train:",  X_5_train.shape, "test:", X_5_test.shape)

        # Classifiers: Tiny, Small, Medium, Large, Huge lstmn models
        model_1 = lstmn.baseline_model(tin_lstm_units, n_timesteps)
        model_2 = lstmn.baseline_model(sml_lstm_units, n_timesteps)
        model_3 = lstmn.baseline_model(med_lstm_units, n_timesteps)
        model_4 = lstmn.baseline_model(lrg_lstm_units, n_timesteps)
        model_5 = lstmn.baseline_model(hug_lstm_units, n_timesteps)

        # Max Voting
        # Split validation set from the training set
        X_1_train, X_1_val, y_1_train, y_1_val = train_test_split(X_1_train, y_1_train, test_size=lstmn.VAL_SPLIT)
        X_2_train, X_2_val, y_2_train, y_2_val = train_test_split(X_2_train, y_2_train, test_size=lstmn.VAL_SPLIT)
        X_3_train, X_3_val, y_3_train, y_3_val = train_test_split(X_3_train, y_3_train, test_size=lstmn.VAL_SPLIT)
        X_4_train, X_4_val, y_4_train, y_4_val = train_test_split(X_4_train, y_4_train, test_size=lstmn.VAL_SPLIT)
        X_5_train, X_5_val, y_5_train, y_5_val = train_test_split(X_5_train, y_5_train, test_size=lstmn.VAL_SPLIT)
        print('Tiny Model', tin_lstm_units, 'units')
        print("X_train:", X_1_train.shape)
        model_1.fit(X_1_train, y_1_train,
                    validation_data=(X_1_val, y_1_val),
                    epochs=lstmn.NUM_EPOCH, batch_size=lstmn.BATCH_SIZE, verbose=2)

        print('Small Model', sml_lstm_units, 'units')
        print("X_train:", X_2_train.shape)
        model_2.fit(X_2_train, y_2_train,
                    validation_data=(X_2_val, y_2_val),
                    epochs=lstmn.NUM_EPOCH, batch_size=lstmn.BATCH_SIZE, verbose=2)

        print('Medium Model', med_lstm_units, 'units')
        print("X_train:", X_3_train.shape)
        model_3.fit(X_3_train, y_3_train,
                    validation_data=(X_3_val, y_3_val),
                    epochs=lstmn.NUM_EPOCH, batch_size=lstmn.BATCH_SIZE, verbose=2)

        print('Large Model', lrg_lstm_units, 'units')
        print("X_train:", X_4_train.shape)
        model_4.fit(X_4_train, y_4_train,
                    validation_data=(X_4_val, y_4_val),
                    epochs=lstmn.NUM_EPOCH, batch_size=lstmn.BATCH_SIZE, verbose=2)

        print('Huge Model', hug_lstm_units, 'units')
        print("X_train:", X_5_train.shape)
        model_5.fit(X_5_train, y_5_train,
                    validation_data=(X_5_val, y_5_val),
                    epochs=lstmn.NUM_EPOCH, batch_size=lstmn.BATCH_SIZE, verbose=2)

        model_1_pred = model_1.predict(X_1_test, batch_size=lstmn.BATCH_SIZE)
        model_2_pred = model_2.predict(X_2_test, batch_size=lstmn.BATCH_SIZE)
        model_3_pred = model_3.predict(X_3_test, batch_size=lstmn.BATCH_SIZE)
        model_4_pred = model_4.predict(X_4_test, batch_size=lstmn.BATCH_SIZE)
        model_5_pred = model_5.predict(X_5_test, batch_size=lstmn.BATCH_SIZE)
        #
        # classify output predictions
        if lstmn.NUM_CLASS == 2:
            model_1_pred = (model_1_pred > 0.5)
            model_2_pred = (model_2_pred > 0.5)
            model_3_pred = (model_3_pred > 0.5)
            model_4_pred = (model_4_pred > 0.5)
            model_5_pred = (model_5_pred > 0.5)
        elif lstmn.NUM_CLASS == 4:
            # Tiny Prediction
            y_ohe = model_1_pred
            model_1_pred = []
            for y in y_ohe:
                mx = 0
                mx_i = None
                for i in range(4):
                    if y[i] > mx:
                        mx_i = i
                        mx = y[i]
                model_1_pred.append(mx_i)
            # Small Prediction
            y_ohe = model_2_pred
            model_2_pred = []
            for y in y_ohe:
                mx = 0
                mx_i = None
                for i in range(4):
                    if y[i] > mx:
                        mx_i = i
                        mx = y[i]
                model_2_pred.append(mx_i)
            # Medium Prediction
            y_ohe = model_3_pred
            model_3_pred = []
            for y in y_ohe:
                mx = 0
                mx_i = None
                for i in range(4):
                    if y[i] > mx:
                        mx_i = i
                        mx = y[i]
                model_3_pred.append(mx_i)
            # Large Prediction
            y_ohe = model_4_pred
            model_4_pred = []
            for y in y_ohe:
                mx = 0
                mx_i = None
                for i in range(4):
                    if y[i] > mx:
                        mx_i = i
                        mx = y[i]
                model_4_pred.append(mx_i)
            # Huge Prediction
            y_ohe = model_5_pred
            model_5_pred = []
            for y in y_ohe:
                mx = 0
                mx_i = None
                for i in range(4):
                    if y[i] > mx:
                        mx_i = i
                        mx = y[i]
                model_5_pred.append(mx_i)
            # Actual
            y_ohe = y_test
            y_test = []
            for y in y_ohe:
                mx = 0
                mx_i = None
                for i in range(4):
                    if y[i] > mx:
                        mx_i = i
                        mx = y[i]
                y_test.append(mx_i)

        print("y_test:     ", y_test)
        print("Tiny   pred:", model_1_pred)
        print("Small  pred:", model_2_pred)
        print("Medium pred:", model_3_pred)
        print("Large  pred:", model_4_pred)
        print("Huge   pred:", model_5_pred)

        final_pred = np.array([])
        for i in range(0, len(X_test)):
            max_vote = mode([model_1_pred[i],
                             model_2_pred[i],
                             model_3_pred[i],
                             model_4_pred[i],
                             model_5_pred[i]])
            final_pred = np.append(final_pred, max_vote[0])


        print("final_pred: ", final_pred)

        # confusion matrix
        cm = confusion_matrix(y_test, final_pred)
        if cm_sum is None:
            cm_sum = cm
        else:
            cm_sum += cm

        score = 0
        sum = 0
        for r in range(cm.shape[0]):
            for c in range(cm.shape[1]):
                sum += cm[r, c]
                if r == c:
                    score += cm[r, c]
        score = score * 100 / sum
        print("score: %.2f%%" % score)
        cvscores.append(score)

    print("\nCross Fold Classification Accuracy:\n%.2f%% (+/- %.2f%%)" % (np.mean(cvscores), np.std(cvscores)))

    # Plot non-normalized confusion matrix
    plt.figure()
    lstmn.plot_confusion_matrix(cm_sum, classes=class_names, title='Confusion matrix, without normalization')

    # Time End
    elapsed_time = time.time()
    hours, rem = divmod(elapsed_time - start_time, 3600)
    minutes, seconds = divmod(rem, 60)
    print("Elapsed Time: {:0>2}:{:0>2}:{:05.2f}".format(int(hours), int(minutes), seconds))

    plt.show()


/media/alexanderfernandes/6686E8B186E882C3/Users/alexanderfernandes/Code/BIOM5405-ClassProject/venv/bin/python3.5 /media/alexanderfernandes/6686E8B186E882C3/Users/alexanderfernandes/Code/BIOM5405-ClassProject/python/src/ML.py
Using TensorFlow backend.
Loading: label | file
1 | als1.tsv
1 | als2.tsv
1 | als3.tsv
1 | als4.tsv
1 | als5.tsv
1 | als6.tsv
1 | als7.tsv
1 | als8.tsv
0 | control1.tsv
0 | control14.tsv
0 | control15.tsv
0 | control16.tsv
0 | control2.tsv
0 | control3.tsv
0 | control4.tsv
0 | control5.tsv
0 | control6.tsv
0 | control7.tsv
~ | file_index.txt
1 | hunt1.tsv
1 | hunt14.tsv
1 | hunt15.tsv
1 | hunt16.tsv
1 | hunt17.tsv
1 | hunt18.tsv
1 | hunt19.tsv
1 | hunt2.tsv
1 | hunt20.tsv
1 | hunt3.tsv
1 | hunt4.tsv
1 | hunt5.tsv
1 | hunt6.tsv
1 | hunt7.tsv
1 | hunt8.tsv
1 | park1.tsv
1 | park14.tsv
1 | park15.tsv
1 | park2.tsv
1 | park3.tsv
1 | park4.tsv
1 | park5.tsv
1 | park6.tsv
1 | park7.tsv
1 | park8.tsv
0 | control8.tsv
X_total = (44, 14000, 20)
y_total =  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]
Number Classes: 1
Cropped Time Series Length: 14000
Number Features: 20

CV Fold 1/5
TRAIN/VAL: 34 [0, 1, 2, 3, 5, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42]
TEST: 10 [4, 6, 7, 11, 15, 23, 25, 26, 27, 43]
Bootstrap Sample Set:
Tiny   | train: (102, 14000, 20) test: (10, 14000, 20)
Small  | train: (102, 14000, 20) test: (10, 14000, 20)
Medium | train: (102, 14000, 20) test: (10, 14000, 20)
Large  | train: (102, 14000, 20) test: (10, 14000, 20)
Huge   | train: (102, 14000, 20) test: (10, 14000, 20)
Tiny Model 2 units
X_train: (71, 14000, 20)
Train on 71 samples, validate on 31 samples
Epoch 1/20
 - 16s - loss: 0.6639 - acc: 0.7746 - val_loss: 0.6512 - val_acc: 0.9032
Epoch 2/20
 - 14s - loss: 0.6645 - acc: 0.7746 - val_loss: 0.6493 - val_acc: 0.9032
Epoch 3/20
 - 14s - loss: 0.6623 - acc: 0.7746 - val_loss: 0.6476 - val_acc: 0.9032
Epoch 4/20
 - 14s - loss: 0.6627 - acc: 0.7887 - val_loss: 0.6458 - val_acc: 0.9032
Epoch 5/20
 - 14s - loss: 0.6604 - acc: 0.7746 - val_loss: 0.6440 - val_acc: 0.9032
Epoch 6/20
 - 14s - loss: 0.6587 - acc: 0.7746 - val_loss: 0.6422 - val_acc: 0.9032
Epoch 7/20
 - 13s - loss: 0.6575 - acc: 0.7746 - val_loss: 0.6404 - val_acc: 0.9032
Epoch 8/20
 - 14s - loss: 0.6554 - acc: 0.7746 - val_loss: 0.6386 - val_acc: 0.9032
Epoch 9/20
 - 14s - loss: 0.6545 - acc: 0.7746 - val_loss: 0.6368 - val_acc: 0.9032
Epoch 10/20
 - 13s - loss: 0.6519 - acc: 0.7746 - val_loss: 0.6350 - val_acc: 0.9032
Epoch 11/20
 - 14s - loss: 0.6520 - acc: 0.7746 - val_loss: 0.6333 - val_acc: 0.9032
Epoch 12/20
 - 14s - loss: 0.6526 - acc: 0.7746 - val_loss: 0.6315 - val_acc: 0.9032
Epoch 13/20
 - 14s - loss: 0.6524 - acc: 0.7746 - val_loss: 0.6297 - val_acc: 0.9032
Epoch 14/20
 - 14s - loss: 0.6499 - acc: 0.7746 - val_loss: 0.6280 - val_acc: 0.9032
Epoch 15/20
 - 14s - loss: 0.6482 - acc: 0.7746 - val_loss: 0.6262 - val_acc: 0.9032
Epoch 16/20
 - 14s - loss: 0.6481 - acc: 0.7746 - val_loss: 0.6244 - val_acc: 0.9032
Epoch 17/20
 - 14s - loss: 0.6446 - acc: 0.7746 - val_loss: 0.6227 - val_acc: 0.9032
Epoch 18/20
 - 14s - loss: 0.6460 - acc: 0.7746 - val_loss: 0.6209 - val_acc: 0.9032
Epoch 19/20
 - 14s - loss: 0.6440 - acc: 0.7746 - val_loss: 0.6192 - val_acc: 0.9032
Epoch 20/20
 - 14s - loss: 0.6432 - acc: 0.7746 - val_loss: 0.6174 - val_acc: 0.9032
Small Model 10 units
X_train: (71, 14000, 20)
Train on 71 samples, validate on 31 samples
Epoch 1/20
 - 15s - loss: 0.7912 - acc: 0.1690 - val_loss: 0.7829 - val_acc: 0.2258
Epoch 2/20
 - 14s - loss: 0.7937 - acc: 0.1690 - val_loss: 0.7778 - val_acc: 0.2258
Epoch 3/20
 - 13s - loss: 0.7840 - acc: 0.1690 - val_loss: 0.7719 - val_acc: 0.2258
Epoch 4/20
 - 14s - loss: 0.7814 - acc: 0.1831 - val_loss: 0.7660 - val_acc: 0.2258
Epoch 5/20
 - 13s - loss: 0.7712 - acc: 0.1831 - val_loss: 0.7603 - val_acc: 0.2258
Epoch 6/20
 - 14s - loss: 0.7708 - acc: 0.1690 - val_loss: 0.7546 - val_acc: 0.2258
Epoch 7/20
 - 14s - loss: 0.7585 - acc: 0.1831 - val_loss: 0.7490 - val_acc: 0.2258
Epoch 8/20
 - 14s - loss: 0.7513 - acc: 0.2113 - val_loss: 0.7433 - val_acc: 0.2258
Epoch 9/20
 - 13s - loss: 0.7433 - acc: 0.2113 - val_loss: 0.7376 - val_acc: 0.2258
Epoch 10/20
 - 14s - loss: 0.7403 - acc: 0.2254 - val_loss: 0.7319 - val_acc: 0.2903
Epoch 11/20
 - 13s - loss: 0.7311 - acc: 0.2676 - val_loss: 0.7262 - val_acc: 0.2903
Epoch 12/20
 - 14s - loss: 0.7256 - acc: 0.2817 - val_loss: 0.7205 - val_acc: 0.2903
Epoch 13/20
 - 14s - loss: 0.7180 - acc: 0.3944 - val_loss: 0.7148 - val_acc: 0.4516
Epoch 14/20
 - 14s - loss: 0.7105 - acc: 0.3803 - val_loss: 0.7090 - val_acc: 0.4839
Epoch 15/20
 - 14s - loss: 0.7031 - acc: 0.4507 - val_loss: 0.7032 - val_acc: 0.4839
Epoch 16/20
 - 13s - loss: 0.6964 - acc: 0.4648 - val_loss: 0.6974 - val_acc: 0.4839
Epoch 17/20
 - 14s - loss: 0.6857 - acc: 0.5634 - val_loss: 0.6916 - val_acc: 0.4839
Epoch 18/20
 - 14s - loss: 0.6817 - acc: 0.5775 - val_loss: 0.6858 - val_acc: 0.5161
Epoch 19/20
 - 13s - loss: 0.6783 - acc: 0.5775 - val_loss: 0.6800 - val_acc: 0.5161
Epoch 20/20
 - 14s - loss: 0.6713 - acc: 0.6620 - val_loss: 0.6744 - val_acc: 0.5161
Medium Model 25 units
X_train: (71, 14000, 20)
Train on 71 samples, validate on 31 samples
Epoch 1/20
 - 15s - loss: 0.8117 - acc: 0.2958 - val_loss: 0.8381 - val_acc: 0.1613
Epoch 2/20
 - 13s - loss: 0.7740 - acc: 0.3380 - val_loss: 0.8104 - val_acc: 0.1613
Epoch 3/20
 - 13s - loss: 0.7741 - acc: 0.3380 - val_loss: 0.7821 - val_acc: 0.2258
Epoch 4/20
 - 13s - loss: 0.7524 - acc: 0.4085 - val_loss: 0.7525 - val_acc: 0.2581
Epoch 5/20
 - 14s - loss: 0.7328 - acc: 0.4366 - val_loss: 0.7244 - val_acc: 0.3548
Epoch 6/20
 - 13s - loss: 0.7073 - acc: 0.5070 - val_loss: 0.6988 - val_acc: 0.5161
Epoch 7/20
 - 13s - loss: 0.6886 - acc: 0.5211 - val_loss: 0.6745 - val_acc: 0.6129
Epoch 8/20
 - 14s - loss: 0.6775 - acc: 0.5775 - val_loss: 0.6514 - val_acc: 0.7097
Epoch 9/20
 - 13s - loss: 0.6822 - acc: 0.5070 - val_loss: 0.6303 - val_acc: 0.7419
Epoch 10/20
 - 14s - loss: 0.6510 - acc: 0.5915 - val_loss: 0.6107 - val_acc: 0.8065
Epoch 11/20
 - 13s - loss: 0.6358 - acc: 0.7042 - val_loss: 0.5928 - val_acc: 0.7419
Epoch 12/20
 - 14s - loss: 0.6218 - acc: 0.7324 - val_loss: 0.5764 - val_acc: 0.9032
Epoch 13/20
 - 14s - loss: 0.6154 - acc: 0.7746 - val_loss: 0.5612 - val_acc: 0.9032
Epoch 14/20
 - 13s - loss: 0.6060 - acc: 0.7465 - val_loss: 0.5473 - val_acc: 0.9032
Epoch 15/20
 - 14s - loss: 0.6005 - acc: 0.7606 - val_loss: 0.5346 - val_acc: 0.9032
Epoch 16/20
 - 13s - loss: 0.5939 - acc: 0.7606 - val_loss: 0.5231 - val_acc: 0.9032
Epoch 17/20
 - 14s - loss: 0.5840 - acc: 0.7746 - val_loss: 0.5126 - val_acc: 0.9032
Epoch 18/20
 - 13s - loss: 0.5793 - acc: 0.7746 - val_loss: 0.5031 - val_acc: 0.9032
Epoch 19/20
 - 13s - loss: 0.5792 - acc: 0.7746 - val_loss: 0.4944 - val_acc: 0.9032
Epoch 20/20
 - 13s - loss: 0.5652 - acc: 0.7746 - val_loss: 0.4866 - val_acc: 0.9032
Large Model 50 units
X_train: (71, 14000, 20)
Train on 71 samples, validate on 31 samples
Epoch 1/20
 - 16s - loss: 0.6621 - acc: 0.8310 - val_loss: 0.6602 - val_acc: 0.7419
Epoch 2/20
 - 14s - loss: 0.6451 - acc: 0.8451 - val_loss: 0.6505 - val_acc: 0.7419
Epoch 3/20
 - 15s - loss: 0.6265 - acc: 0.8451 - val_loss: 0.6422 - val_acc: 0.7419
Epoch 4/20
 - 14s - loss: 0.6142 - acc: 0.8451 - val_loss: 0.6357 - val_acc: 0.7419
Epoch 5/20
 - 15s - loss: 0.6067 - acc: 0.8451 - val_loss: 0.6311 - val_acc: 0.7419
Epoch 6/20
 - 14s - loss: 0.6006 - acc: 0.8451 - val_loss: 0.6276 - val_acc: 0.7419
Epoch 7/20
 - 14s - loss: 0.5930 - acc: 0.8451 - val_loss: 0.6247 - val_acc: 0.7419
Epoch 8/20
 - 14s - loss: 0.5881 - acc: 0.8451 - val_loss: 0.6224 - val_acc: 0.7419
Epoch 9/20
 - 15s - loss: 0.5844 - acc: 0.8451 - val_loss: 0.6202 - val_acc: 0.7419
Epoch 10/20
 - 14s - loss: 0.5825 - acc: 0.8451 - val_loss: 0.6181 - val_acc: 0.7419
Epoch 11/20
 - 15s - loss: 0.5785 - acc: 0.8451 - val_loss: 0.6161 - val_acc: 0.7419
Epoch 12/20
 - 14s - loss: 0.5753 - acc: 0.8451 - val_loss: 0.6140 - val_acc: 0.7419
Epoch 13/20
 - 14s - loss: 0.5724 - acc: 0.8451 - val_loss: 0.6120 - val_acc: 0.7419
Epoch 14/20
 - 14s - loss: 0.5684 - acc: 0.8451 - val_loss: 0.6099 - val_acc: 0.7419
Epoch 15/20
 - 14s - loss: 0.5640 - acc: 0.8451 - val_loss: 0.6078 - val_acc: 0.7419
Epoch 16/20
 - 14s - loss: 0.5605 - acc: 0.8451 - val_loss: 0.6058 - val_acc: 0.7419
Epoch 17/20
 - 15s - loss: 0.5567 - acc: 0.8451 - val_loss: 0.6037 - val_acc: 0.7419
Epoch 18/20
 - 14s - loss: 0.5521 - acc: 0.8451 - val_loss: 0.6017 - val_acc: 0.7419
Epoch 19/20
 - 14s - loss: 0.5483 - acc: 0.8451 - val_loss: 0.5996 - val_acc: 0.7419
Epoch 20/20
 - 14s - loss: 0.5458 - acc: 0.8451 - val_loss: 0.5976 - val_acc: 0.7419
Huge Model 100 units
X_train: (71, 14000, 20)
Train on 71 samples, validate on 31 samples
Epoch 1/20
 - 18s - loss: 0.7956 - acc: 0.1972 - val_loss: 0.6499 - val_acc: 0.7742
Epoch 2/20
 - 16s - loss: 0.6430 - acc: 0.7465 - val_loss: 0.5949 - val_acc: 0.8065
Epoch 3/20
 - 19s - loss: 0.5773 - acc: 0.8169 - val_loss: 0.5663 - val_acc: 0.8065
Epoch 4/20
 - 17s - loss: 0.5536 - acc: 0.8169 - val_loss: 0.5506 - val_acc: 0.8065
Epoch 5/20
 - 17s - loss: 0.5359 - acc: 0.8169 - val_loss: 0.5390 - val_acc: 0.8065
Epoch 6/20
 - 16s - loss: 0.5252 - acc: 0.8169 - val_loss: 0.5300 - val_acc: 0.8065
Epoch 7/20
 - 16s - loss: 0.5170 - acc: 0.8169 - val_loss: 0.5226 - val_acc: 0.8065
Epoch 8/20
 - 17s - loss: 0.5093 - acc: 0.8169 - val_loss: 0.5166 - val_acc: 0.8065
Epoch 9/20
 - 17s - loss: 0.5012 - acc: 0.8169 - val_loss: 0.5118 - val_acc: 0.8065
Epoch 10/20
 - 16s - loss: 0.4992 - acc: 0.8169 - val_loss: 0.5077 - val_acc: 0.8065
Epoch 11/20
 - 16s - loss: 0.4943 - acc: 0.8169 - val_loss: 0.5042 - val_acc: 0.8065
Epoch 12/20
 - 16s - loss: 0.4884 - acc: 0.8169 - val_loss: 0.5013 - val_acc: 0.8065
Epoch 13/20
 - 16s - loss: 0.4846 - acc: 0.8169 - val_loss: 0.4989 - val_acc: 0.8065
Epoch 14/20
 - 16s - loss: 0.4818 - acc: 0.8169 - val_loss: 0.4969 - val_acc: 0.8065
Epoch 15/20
 - 16s - loss: 0.4798 - acc: 0.8169 - val_loss: 0.4953 - val_acc: 0.8065
Epoch 16/20
 - 16s - loss: 0.4774 - acc: 0.8169 - val_loss: 0.4941 - val_acc: 0.8065
Epoch 17/20
 - 16s - loss: 0.4759 - acc: 0.8169 - val_loss: 0.4934 - val_acc: 0.8065
Epoch 18/20
 - 17s - loss: 0.4706 - acc: 0.8169 - val_loss: 0.4931 - val_acc: 0.8065
Epoch 19/20
 - 16s - loss: 0.4724 - acc: 0.8169 - val_loss: 0.4931 - val_acc: 0.8065
Epoch 20/20
 - 16s - loss: 0.4706 - acc: 0.8169 - val_loss: 0.4935 - val_acc: 0.8065
y_test:      [1 1 1 0 0 1 1 1 1 0]
Tiny   pred: [[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]]
Small  pred: [[False]
 [False]
 [ True]
 [False]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]]
Medium pred: [[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]]
Large  pred: [[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]]
Huge   pred: [[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]]
final_pred:  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
score: 70.00%

CV Fold 2/5
TRAIN/VAL: 35 [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 23, 25, 26, 27, 28, 30, 32, 34, 35, 36, 37, 38, 39, 42, 43]
TEST: 9 [9, 17, 22, 24, 29, 31, 33, 40, 41]
Bootstrap Sample Set:
Tiny   | train: (105, 14000, 20) test: (9, 14000, 20)
Small  | train: (105, 14000, 20) test: (9, 14000, 20)
Medium | train: (105, 14000, 20) test: (9, 14000, 20)
Large  | train: (105, 14000, 20) test: (9, 14000, 20)
Huge   | train: (105, 14000, 20) test: (9, 14000, 20)
Tiny Model 2 units
X_train: (73, 14000, 20)
Train on 73 samples, validate on 32 samples
Epoch 1/20
 - 16s - loss: 0.6607 - acc: 0.7260 - val_loss: 0.6676 - val_acc: 0.6875
Epoch 2/20
 - 14s - loss: 0.6607 - acc: 0.7260 - val_loss: 0.6667 - val_acc: 0.6875
Epoch 3/20
 - 14s - loss: 0.6594 - acc: 0.7260 - val_loss: 0.6658 - val_acc: 0.6875
Epoch 4/20
 - 14s - loss: 0.6576 - acc: 0.7260 - val_loss: 0.6650 - val_acc: 0.6875
Epoch 5/20
 - 14s - loss: 0.6576 - acc: 0.7260 - val_loss: 0.6642 - val_acc: 0.6875
Epoch 6/20
 - 13s - loss: 0.6565 - acc: 0.7260 - val_loss: 0.6634 - val_acc: 0.6875
Epoch 7/20
 - 14s - loss: 0.6543 - acc: 0.7260 - val_loss: 0.6626 - val_acc: 0.6875
Epoch 8/20
 - 14s - loss: 0.6543 - acc: 0.7260 - val_loss: 0.6619 - val_acc: 0.6875
Epoch 9/20
 - 14s - loss: 0.6542 - acc: 0.7260 - val_loss: 0.6612 - val_acc: 0.6875
Epoch 10/20
 - 14s - loss: 0.6523 - acc: 0.7260 - val_loss: 0.6605 - val_acc: 0.6875
Epoch 11/20
 - 14s - loss: 0.6525 - acc: 0.7260 - val_loss: 0.6599 - val_acc: 0.6875
Epoch 12/20
 - 14s - loss: 0.6516 - acc: 0.7260 - val_loss: 0.6592 - val_acc: 0.6875
Epoch 13/20
 - 14s - loss: 0.6508 - acc: 0.7260 - val_loss: 0.6586 - val_acc: 0.6875
Epoch 14/20
 - 14s - loss: 0.6509 - acc: 0.7260 - val_loss: 0.6579 - val_acc: 0.6875
Epoch 15/20
 - 14s - loss: 0.6478 - acc: 0.7260 - val_loss: 0.6573 - val_acc: 0.6875
Epoch 16/20
 - 14s - loss: 0.6478 - acc: 0.7260 - val_loss: 0.6567 - val_acc: 0.6875
Epoch 17/20
 - 14s - loss: 0.6475 - acc: 0.7260 - val_loss: 0.6560 - val_acc: 0.6875
Epoch 18/20
 - 14s - loss: 0.6456 - acc: 0.7260 - val_loss: 0.6554 - val_acc: 0.6875
Epoch 19/20
 - 15s - loss: 0.6456 - acc: 0.7260 - val_loss: 0.6548 - val_acc: 0.6875
Epoch 20/20
 - 14s - loss: 0.6456 - acc: 0.7260 - val_loss: 0.6542 - val_acc: 0.6875
Small Model 10 units
X_train: (73, 14000, 20)
Train on 73 samples, validate on 32 samples
Epoch 1/20
 - 16s - loss: 0.6559 - acc: 0.6712 - val_loss: 0.6495 - val_acc: 0.7812
Epoch 2/20
 - 13s - loss: 0.6635 - acc: 0.6575 - val_loss: 0.6444 - val_acc: 0.7812
Epoch 3/20
 - 13s - loss: 0.6550 - acc: 0.6986 - val_loss: 0.6400 - val_acc: 0.7812
Epoch 4/20
 - 13s - loss: 0.6556 - acc: 0.6849 - val_loss: 0.6351 - val_acc: 0.7812
Epoch 5/20
 - 13s - loss: 0.6530 - acc: 0.6849 - val_loss: 0.6305 - val_acc: 0.7812
Epoch 6/20
 - 13s - loss: 0.6534 - acc: 0.6849 - val_loss: 0.6259 - val_acc: 0.7812
Epoch 7/20
 - 13s - loss: 0.6481 - acc: 0.6849 - val_loss: 0.6216 - val_acc: 0.7812
Epoch 8/20
 - 14s - loss: 0.6481 - acc: 0.6849 - val_loss: 0.6173 - val_acc: 0.7812
Epoch 9/20
 - 13s - loss: 0.6465 - acc: 0.6849 - val_loss: 0.6133 - val_acc: 0.7812
Epoch 10/20
 - 13s - loss: 0.6478 - acc: 0.6849 - val_loss: 0.6093 - val_acc: 0.7812
Epoch 11/20
 - 14s - loss: 0.6467 - acc: 0.6849 - val_loss: 0.6056 - val_acc: 0.7812
Epoch 12/20
 - 14s - loss: 0.6434 - acc: 0.6849 - val_loss: 0.6020 - val_acc: 0.7812
Epoch 13/20
 - 14s - loss: 0.6443 - acc: 0.6849 - val_loss: 0.5985 - val_acc: 0.7812
Epoch 14/20
 - 14s - loss: 0.6297 - acc: 0.6849 - val_loss: 0.5952 - val_acc: 0.7812
Epoch 15/20
 - 13s - loss: 0.6365 - acc: 0.6849 - val_loss: 0.5920 - val_acc: 0.7812
Epoch 16/20
 - 14s - loss: 0.6344 - acc: 0.6849 - val_loss: 0.5890 - val_acc: 0.7812
Epoch 17/20
 - 13s - loss: 0.6320 - acc: 0.6849 - val_loss: 0.5861 - val_acc: 0.7812
Epoch 18/20
 - 13s - loss: 0.6375 - acc: 0.6849 - val_loss: 0.5834 - val_acc: 0.7812
Epoch 19/20
 - 13s - loss: 0.6308 - acc: 0.6849 - val_loss: 0.5809 - val_acc: 0.7812
Epoch 20/20
 - 13s - loss: 0.6341 - acc: 0.6849 - val_loss: 0.5785 - val_acc: 0.7812
Medium Model 25 units
X_train: (73, 14000, 20)
Train on 73 samples, validate on 32 samples
Epoch 1/20
 - 16s - loss: 0.7098 - acc: 0.3562 - val_loss: 0.6993 - val_acc: 0.3750
Epoch 2/20
 - 13s - loss: 0.7055 - acc: 0.3014 - val_loss: 0.6956 - val_acc: 0.4688
Epoch 3/20
 - 13s - loss: 0.6929 - acc: 0.5068 - val_loss: 0.6920 - val_acc: 0.5312
Epoch 4/20
 - 13s - loss: 0.6871 - acc: 0.5890 - val_loss: 0.6887 - val_acc: 0.5938
Epoch 5/20
 - 13s - loss: 0.6806 - acc: 0.6986 - val_loss: 0.6856 - val_acc: 0.5938
Epoch 6/20
 - 13s - loss: 0.6758 - acc: 0.7123 - val_loss: 0.6827 - val_acc: 0.6250
Epoch 7/20
 - 13s - loss: 0.6710 - acc: 0.6986 - val_loss: 0.6802 - val_acc: 0.6250
Epoch 8/20
 - 13s - loss: 0.6623 - acc: 0.7534 - val_loss: 0.6779 - val_acc: 0.6250
Epoch 9/20
 - 13s - loss: 0.6541 - acc: 0.7397 - val_loss: 0.6758 - val_acc: 0.6250
Epoch 10/20
 - 13s - loss: 0.6513 - acc: 0.7534 - val_loss: 0.6740 - val_acc: 0.6250
Epoch 11/20
 - 14s - loss: 0.6482 - acc: 0.7534 - val_loss: 0.6724 - val_acc: 0.6250
Epoch 12/20
 - 13s - loss: 0.6336 - acc: 0.7534 - val_loss: 0.6709 - val_acc: 0.6250
Epoch 13/20
 - 13s - loss: 0.6353 - acc: 0.7534 - val_loss: 0.6697 - val_acc: 0.6250
Epoch 14/20
 - 13s - loss: 0.6334 - acc: 0.7534 - val_loss: 0.6686 - val_acc: 0.6250
Epoch 15/20
 - 13s - loss: 0.6279 - acc: 0.7534 - val_loss: 0.6676 - val_acc: 0.6250
Epoch 16/20
 - 13s - loss: 0.6241 - acc: 0.7534 - val_loss: 0.6668 - val_acc: 0.6250
Epoch 17/20
 - 13s - loss: 0.6181 - acc: 0.7534 - val_loss: 0.6661 - val_acc: 0.6250
Epoch 18/20
 - 13s - loss: 0.6153 - acc: 0.7534 - val_loss: 0.6656 - val_acc: 0.6250
Epoch 19/20
 - 13s - loss: 0.6123 - acc: 0.7534 - val_loss: 0.6651 - val_acc: 0.6250
Epoch 20/20
 - 13s - loss: 0.6079 - acc: 0.7534 - val_loss: 0.6648 - val_acc: 0.6250
Large Model 50 units
X_train: (73, 14000, 20)
Train on 73 samples, validate on 32 samples
Epoch 1/20
 - 18s - loss: 0.6992 - acc: 0.3836 - val_loss: 0.6920 - val_acc: 0.4062
Epoch 2/20
 - 15s - loss: 0.6921 - acc: 0.5890 - val_loss: 0.6872 - val_acc: 0.6562
Epoch 3/20
 - 14s - loss: 0.6839 - acc: 0.7123 - val_loss: 0.6834 - val_acc: 0.6562
Epoch 4/20
 - 14s - loss: 0.6771 - acc: 0.7397 - val_loss: 0.6805 - val_acc: 0.6562
Epoch 5/20
 - 14s - loss: 0.6748 - acc: 0.7260 - val_loss: 0.6780 - val_acc: 0.6562
Epoch 6/20
 - 14s - loss: 0.6702 - acc: 0.7397 - val_loss: 0.6760 - val_acc: 0.6562
Epoch 7/20
 - 14s - loss: 0.6648 - acc: 0.7397 - val_loss: 0.6744 - val_acc: 0.6562
Epoch 8/20
 - 14s - loss: 0.6607 - acc: 0.7397 - val_loss: 0.6729 - val_acc: 0.6562
Epoch 9/20
 - 16s - loss: 0.6585 - acc: 0.7397 - val_loss: 0.6715 - val_acc: 0.6562
Epoch 10/20
 - 14s - loss: 0.6571 - acc: 0.7397 - val_loss: 0.6702 - val_acc: 0.6562
Epoch 11/20
 - 15s - loss: 0.6541 - acc: 0.7397 - val_loss: 0.6690 - val_acc: 0.6562
Epoch 12/20
 - 14s - loss: 0.6530 - acc: 0.7397 - val_loss: 0.6677 - val_acc: 0.6562
Epoch 13/20
 - 14s - loss: 0.6493 - acc: 0.7397 - val_loss: 0.6665 - val_acc: 0.6562
Epoch 14/20
 - 15s - loss: 0.6486 - acc: 0.7397 - val_loss: 0.6652 - val_acc: 0.6562
Epoch 15/20
 - 16s - loss: 0.6462 - acc: 0.7397 - val_loss: 0.6639 - val_acc: 0.6562
Epoch 16/20
 - 14s - loss: 0.6434 - acc: 0.7397 - val_loss: 0.6627 - val_acc: 0.6562
Epoch 17/20
 - 14s - loss: 0.6421 - acc: 0.7397 - val_loss: 0.6615 - val_acc: 0.6562
Epoch 18/20
 - 15s - loss: 0.6401 - acc: 0.7397 - val_loss: 0.6603 - val_acc: 0.6562
Epoch 19/20
 - 14s - loss: 0.6366 - acc: 0.7397 - val_loss: 0.6592 - val_acc: 0.6562
Epoch 20/20
 - 15s - loss: 0.6360 - acc: 0.7397 - val_loss: 0.6581 - val_acc: 0.6562
Huge Model 100 units
X_train: (73, 14000, 20)
Train on 73 samples, validate on 32 samples
Epoch 1/20
 - 20s - loss: 0.6700 - acc: 0.7123 - val_loss: 0.6847 - val_acc: 0.5625
Epoch 2/20
 - 17s - loss: 0.6230 - acc: 0.7808 - val_loss: 0.6900 - val_acc: 0.5625
Epoch 3/20
 - 16s - loss: 0.5873 - acc: 0.7808 - val_loss: 0.7022 - val_acc: 0.5625
Epoch 4/20
 - 17s - loss: 0.5711 - acc: 0.7808 - val_loss: 0.7181 - val_acc: 0.5625
Epoch 5/20
 - 17s - loss: 0.5426 - acc: 0.7808 - val_loss: 0.7333 - val_acc: 0.5625
Epoch 6/20
 - 16s - loss: 0.5450 - acc: 0.7808 - val_loss: 0.7457 - val_acc: 0.5625
Epoch 7/20
 - 16s - loss: 0.5347 - acc: 0.7808 - val_loss: 0.7554 - val_acc: 0.5625
Epoch 8/20
 - 16s - loss: 0.5356 - acc: 0.7808 - val_loss: 0.7636 - val_acc: 0.5625
Epoch 9/20
 - 17s - loss: 0.5329 - acc: 0.7808 - val_loss: 0.7709 - val_acc: 0.5625
Epoch 10/20
 - 17s - loss: 0.5266 - acc: 0.7808 - val_loss: 0.7780 - val_acc: 0.5625
Epoch 11/20
 - 17s - loss: 0.5248 - acc: 0.7808 - val_loss: 0.7855 - val_acc: 0.5625
Epoch 12/20
 - 16s - loss: 0.5255 - acc: 0.7808 - val_loss: 0.7929 - val_acc: 0.5625
Epoch 13/20
 - 17s - loss: 0.5244 - acc: 0.7808 - val_loss: 0.8005 - val_acc: 0.5625
Epoch 14/20
 - 16s - loss: 0.5279 - acc: 0.7808 - val_loss: 0.8075 - val_acc: 0.5625
Epoch 15/20
 - 16s - loss: 0.5248 - acc: 0.7808 - val_loss: 0.8137 - val_acc: 0.5625
Epoch 16/20
 - 17s - loss: 0.5249 - acc: 0.7808 - val_loss: 0.8188 - val_acc: 0.5625
Epoch 17/20
 - 17s - loss: 0.5231 - acc: 0.7808 - val_loss: 0.8229 - val_acc: 0.5625
Epoch 18/20
 - 17s - loss: 0.5231 - acc: 0.7808 - val_loss: 0.8257 - val_acc: 0.5625
Epoch 19/20
 - 16s - loss: 0.5244 - acc: 0.7808 - val_loss: 0.8273 - val_acc: 0.5625
Epoch 20/20
 - 17s - loss: 0.5242 - acc: 0.7808 - val_loss: 0.8273 - val_acc: 0.5625
y_test:      [0 0 1 1 1 1 1 1 1]
Tiny   pred: [[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]]
Small  pred: [[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]]
Medium pred: [[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]]
Large  pred: [[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]]
Huge   pred: [[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]]
final_pred:  [1. 1. 1. 1. 1. 1. 1. 1. 1.]
score: 77.78%

CV Fold 3/5
TRAIN/VAL: 35 [1, 2, 4, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43]
TEST: 9 [0, 3, 5, 10, 14, 18, 21, 36, 37]
Bootstrap Sample Set:
Tiny   | train: (105, 14000, 20) test: (9, 14000, 20)
Small  | train: (105, 14000, 20) test: (9, 14000, 20)
Medium | train: (105, 14000, 20) test: (9, 14000, 20)
Large  | train: (105, 14000, 20) test: (9, 14000, 20)
Huge   | train: (105, 14000, 20) test: (9, 14000, 20)
Tiny Model 2 units
X_train: (73, 14000, 20)
Train on 73 samples, validate on 32 samples
Epoch 1/20
 - 18s - loss: 0.6709 - acc: 0.5753 - val_loss: 0.6417 - val_acc: 0.6250
Epoch 2/20
 - 14s - loss: 0.6519 - acc: 0.6712 - val_loss: 0.6366 - val_acc: 0.6250
Epoch 3/20
 - 14s - loss: 0.6648 - acc: 0.5890 - val_loss: 0.6312 - val_acc: 0.7500
Epoch 4/20
 - 14s - loss: 0.6431 - acc: 0.6849 - val_loss: 0.6260 - val_acc: 0.7500
Epoch 5/20
 - 14s - loss: 0.6462 - acc: 0.6438 - val_loss: 0.6206 - val_acc: 0.8125
Epoch 6/20
 - 14s - loss: 0.6562 - acc: 0.6438 - val_loss: 0.6153 - val_acc: 0.8125
Epoch 7/20
 - 14s - loss: 0.6469 - acc: 0.6849 - val_loss: 0.6102 - val_acc: 0.8125
Epoch 8/20
 - 14s - loss: 0.6381 - acc: 0.6849 - val_loss: 0.6054 - val_acc: 0.8125
Epoch 9/20
 - 14s - loss: 0.6250 - acc: 0.7397 - val_loss: 0.6010 - val_acc: 0.8125
Epoch 10/20
 - 14s - loss: 0.6369 - acc: 0.6986 - val_loss: 0.5971 - val_acc: 0.7812
Epoch 11/20
 - 14s - loss: 0.6199 - acc: 0.7123 - val_loss: 0.5938 - val_acc: 0.7812
Epoch 12/20
 - 14s - loss: 0.6401 - acc: 0.6986 - val_loss: 0.5911 - val_acc: 0.7812
Epoch 13/20
 - 14s - loss: 0.6238 - acc: 0.7260 - val_loss: 0.5887 - val_acc: 0.7812
Epoch 14/20
 - 13s - loss: 0.6165 - acc: 0.7397 - val_loss: 0.5866 - val_acc: 0.7812
Epoch 15/20
 - 14s - loss: 0.6357 - acc: 0.6986 - val_loss: 0.5848 - val_acc: 0.7812
Epoch 16/20
 - 13s - loss: 0.6324 - acc: 0.6575 - val_loss: 0.5832 - val_acc: 0.7812
Epoch 17/20
 - 14s - loss: 0.6291 - acc: 0.6849 - val_loss: 0.5816 - val_acc: 0.7812
Epoch 18/20
 - 14s - loss: 0.6077 - acc: 0.7397 - val_loss: 0.5801 - val_acc: 0.7812
Epoch 19/20
 - 14s - loss: 0.6080 - acc: 0.7397 - val_loss: 0.5786 - val_acc: 0.7812
Epoch 20/20
 - 14s - loss: 0.6073 - acc: 0.7397 - val_loss: 0.5771 - val_acc: 0.7812
Small Model 10 units
X_train: (73, 14000, 20)
Train on 73 samples, validate on 32 samples
Epoch 1/20
 - 17s - loss: 0.6807 - acc: 0.5205 - val_loss: 0.6625 - val_acc: 0.6875
Epoch 2/20
 - 13s - loss: 0.6850 - acc: 0.6164 - val_loss: 0.6539 - val_acc: 0.7812
Epoch 3/20
 - 14s - loss: 0.6855 - acc: 0.5479 - val_loss: 0.6470 - val_acc: 0.6562
Epoch 4/20
 - 14s - loss: 0.6623 - acc: 0.6027 - val_loss: 0.6415 - val_acc: 0.6562
Epoch 5/20
 - 13s - loss: 0.6713 - acc: 0.6438 - val_loss: 0.6372 - val_acc: 0.6562
Epoch 6/20
 - 14s - loss: 0.6455 - acc: 0.6712 - val_loss: 0.6342 - val_acc: 0.6562
Epoch 7/20
 - 13s - loss: 0.6446 - acc: 0.6849 - val_loss: 0.6320 - val_acc: 0.6875
Epoch 8/20
 - 13s - loss: 0.6302 - acc: 0.7534 - val_loss: 0.6303 - val_acc: 0.6875
Epoch 9/20
 - 14s - loss: 0.6316 - acc: 0.7260 - val_loss: 0.6290 - val_acc: 0.6875
Epoch 10/20
 - 13s - loss: 0.6214 - acc: 0.7534 - val_loss: 0.6278 - val_acc: 0.6875
Epoch 11/20
 - 13s - loss: 0.6114 - acc: 0.7534 - val_loss: 0.6266 - val_acc: 0.6875
Epoch 12/20
 - 14s - loss: 0.6040 - acc: 0.7397 - val_loss: 0.6253 - val_acc: 0.6875
Epoch 13/20
 - 14s - loss: 0.6082 - acc: 0.7671 - val_loss: 0.6241 - val_acc: 0.6875
Epoch 14/20
 - 14s - loss: 0.6046 - acc: 0.7671 - val_loss: 0.6229 - val_acc: 0.6875
Epoch 15/20
 - 14s - loss: 0.5994 - acc: 0.7671 - val_loss: 0.6218 - val_acc: 0.6875
Epoch 16/20
 - 14s - loss: 0.5847 - acc: 0.7808 - val_loss: 0.6207 - val_acc: 0.6875
Epoch 17/20
 - 14s - loss: 0.5826 - acc: 0.7808 - val_loss: 0.6197 - val_acc: 0.6875
Epoch 18/20
 - 13s - loss: 0.5806 - acc: 0.7671 - val_loss: 0.6188 - val_acc: 0.6875
Epoch 19/20
 - 13s - loss: 0.5771 - acc: 0.7671 - val_loss: 0.6181 - val_acc: 0.6875
Epoch 20/20
 - 13s - loss: 0.5817 - acc: 0.7671 - val_loss: 0.6174 - val_acc: 0.6875
Medium Model 25 units
X_train: (73, 14000, 20)
Train on 73 samples, validate on 32 samples
Epoch 1/20
 - 17s - loss: 0.7381 - acc: 0.2192 - val_loss: 0.7194 - val_acc: 0.3438
Epoch 2/20
 - 13s - loss: 0.7285 - acc: 0.2740 - val_loss: 0.7143 - val_acc: 0.3438
Epoch 3/20
 - 13s - loss: 0.7245 - acc: 0.2466 - val_loss: 0.7089 - val_acc: 0.3438
Epoch 4/20
 - 13s - loss: 0.7192 - acc: 0.2329 - val_loss: 0.7032 - val_acc: 0.3438
Epoch 5/20
 - 13s - loss: 0.7068 - acc: 0.2466 - val_loss: 0.6977 - val_acc: 0.3750
Epoch 6/20
 - 13s - loss: 0.6975 - acc: 0.4521 - val_loss: 0.6926 - val_acc: 0.5312
Epoch 7/20
 - 13s - loss: 0.6916 - acc: 0.5342 - val_loss: 0.6879 - val_acc: 0.6250
Epoch 8/20
 - 13s - loss: 0.6838 - acc: 0.6301 - val_loss: 0.6834 - val_acc: 0.6562
Epoch 9/20
 - 13s - loss: 0.6758 - acc: 0.6712 - val_loss: 0.6792 - val_acc: 0.6562
Epoch 10/20
 - 13s - loss: 0.6681 - acc: 0.7808 - val_loss: 0.6753 - val_acc: 0.6562
Epoch 11/20
 - 13s - loss: 0.6653 - acc: 0.7397 - val_loss: 0.6717 - val_acc: 0.6562
Epoch 12/20
 - 13s - loss: 0.6549 - acc: 0.7671 - val_loss: 0.6684 - val_acc: 0.6562
Epoch 13/20
 - 13s - loss: 0.6518 - acc: 0.7808 - val_loss: 0.6653 - val_acc: 0.6562
Epoch 14/20
 - 13s - loss: 0.6460 - acc: 0.7808 - val_loss: 0.6626 - val_acc: 0.6562
Epoch 15/20
 - 13s - loss: 0.6406 - acc: 0.7808 - val_loss: 0.6601 - val_acc: 0.6562
Epoch 16/20
 - 13s - loss: 0.6402 - acc: 0.7671 - val_loss: 0.6579 - val_acc: 0.6562
Epoch 17/20
 - 13s - loss: 0.6310 - acc: 0.7808 - val_loss: 0.6559 - val_acc: 0.6562
Epoch 18/20
 - 13s - loss: 0.6276 - acc: 0.7808 - val_loss: 0.6542 - val_acc: 0.6562
Epoch 19/20
 - 13s - loss: 0.6234 - acc: 0.7808 - val_loss: 0.6528 - val_acc: 0.6562
Epoch 20/20
 - 13s - loss: 0.6201 - acc: 0.7808 - val_loss: 0.6516 - val_acc: 0.6562
Large Model 50 units
X_train: (73, 14000, 20)
Train on 73 samples, validate on 32 samples
Epoch 1/20
 - 19s - loss: 0.7150 - acc: 0.4384 - val_loss: 0.7192 - val_acc: 0.3750
Epoch 2/20
 - 14s - loss: 0.7008 - acc: 0.4795 - val_loss: 0.7057 - val_acc: 0.4688
Epoch 3/20
 - 14s - loss: 0.6997 - acc: 0.5342 - val_loss: 0.6926 - val_acc: 0.5000
Epoch 4/20
 - 14s - loss: 0.6814 - acc: 0.5890 - val_loss: 0.6802 - val_acc: 0.5625
Epoch 5/20
 - 14s - loss: 0.6745 - acc: 0.5753 - val_loss: 0.6681 - val_acc: 0.6875
Epoch 6/20
 - 14s - loss: 0.6604 - acc: 0.6438 - val_loss: 0.6574 - val_acc: 0.7500
Epoch 7/20
 - 14s - loss: 0.6522 - acc: 0.7260 - val_loss: 0.6475 - val_acc: 0.7500
Epoch 8/20
 - 14s - loss: 0.6433 - acc: 0.7534 - val_loss: 0.6383 - val_acc: 0.7500
Epoch 9/20
 - 14s - loss: 0.6344 - acc: 0.7397 - val_loss: 0.6299 - val_acc: 0.7500
Epoch 10/20
 - 14s - loss: 0.6318 - acc: 0.7397 - val_loss: 0.6222 - val_acc: 0.7500
Epoch 11/20
 - 14s - loss: 0.6225 - acc: 0.7397 - val_loss: 0.6151 - val_acc: 0.7500
Epoch 12/20
 - 15s - loss: 0.6148 - acc: 0.7397 - val_loss: 0.6086 - val_acc: 0.7500
Epoch 13/20
 - 14s - loss: 0.6118 - acc: 0.7397 - val_loss: 0.6027 - val_acc: 0.7500
Epoch 14/20
 - 14s - loss: 0.6038 - acc: 0.7397 - val_loss: 0.5973 - val_acc: 0.7500
Epoch 15/20
 - 14s - loss: 0.5980 - acc: 0.7397 - val_loss: 0.5926 - val_acc: 0.7500
Epoch 16/20
 - 15s - loss: 0.5965 - acc: 0.7397 - val_loss: 0.5884 - val_acc: 0.7500
Epoch 17/20
 - 14s - loss: 0.5939 - acc: 0.7397 - val_loss: 0.5848 - val_acc: 0.7500
Epoch 18/20
 - 14s - loss: 0.5905 - acc: 0.7397 - val_loss: 0.5817 - val_acc: 0.7500
Epoch 19/20
 - 14s - loss: 0.5860 - acc: 0.7397 - val_loss: 0.5790 - val_acc: 0.7500
Epoch 20/20
 - 16s - loss: 0.5856 - acc: 0.7397 - val_loss: 0.5768 - val_acc: 0.7500
Huge Model 100 units
X_train: (73, 14000, 20)
Train on 73 samples, validate on 32 samples
Epoch 1/20
 - 24s - loss: 0.6635 - acc: 0.6575 - val_loss: 0.6065 - val_acc: 0.7500
Epoch 2/20
 - 28s - loss: 0.6165 - acc: 0.7397 - val_loss: 0.5874 - val_acc: 0.7500
Epoch 3/20
 - 16s - loss: 0.5884 - acc: 0.7397 - val_loss: 0.5792 - val_acc: 0.7500
Epoch 4/20
 - 16s - loss: 0.5856 - acc: 0.7397 - val_loss: 0.5742 - val_acc: 0.7500
Epoch 5/20
 - 17s - loss: 0.5754 - acc: 0.7397 - val_loss: 0.5706 - val_acc: 0.7500
Epoch 6/20
 - 16s - loss: 0.5762 - acc: 0.7397 - val_loss: 0.5679 - val_acc: 0.7500
Epoch 7/20
 - 16s - loss: 0.5741 - acc: 0.7397 - val_loss: 0.5658 - val_acc: 0.7500
Epoch 8/20
 - 16s - loss: 0.5740 - acc: 0.7397 - val_loss: 0.5641 - val_acc: 0.7500
Epoch 9/20
 - 17s - loss: 0.5726 - acc: 0.7397 - val_loss: 0.5630 - val_acc: 0.7500
Epoch 10/20
 - 16s - loss: 0.5698 - acc: 0.7397 - val_loss: 0.5622 - val_acc: 0.7500
Epoch 11/20
 - 17s - loss: 0.5754 - acc: 0.7397 - val_loss: 0.5618 - val_acc: 0.7500
Epoch 12/20
 - 16s - loss: 0.5685 - acc: 0.7397 - val_loss: 0.5616 - val_acc: 0.7500
Epoch 13/20
 - 17s - loss: 0.5720 - acc: 0.7397 - val_loss: 0.5616 - val_acc: 0.7500
Epoch 14/20
 - 16s - loss: 0.5720 - acc: 0.7397 - val_loss: 0.5616 - val_acc: 0.7500
Epoch 15/20
 - 16s - loss: 0.5678 - acc: 0.7397 - val_loss: 0.5614 - val_acc: 0.7500
Epoch 16/20
 - 17s - loss: 0.5679 - acc: 0.7397 - val_loss: 0.5612 - val_acc: 0.7500
Epoch 17/20
 - 16s - loss: 0.5646 - acc: 0.7397 - val_loss: 0.5608 - val_acc: 0.7500
Epoch 18/20
 - 16s - loss: 0.5676 - acc: 0.7397 - val_loss: 0.5604 - val_acc: 0.7500
Epoch 19/20
 - 17s - loss: 0.5662 - acc: 0.7397 - val_loss: 0.5598 - val_acc: 0.7500
Epoch 20/20
 - 17s - loss: 0.5662 - acc: 0.7397 - val_loss: 0.5592 - val_acc: 0.7500
y_test:      [1 1 1 0 0 1 1 1 1]
Tiny   pred: [[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]]
Small  pred: [[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]]
Medium pred: [[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]]
Large  pred: [[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]]
Huge   pred: [[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]]
final_pred:  [1. 1. 1. 1. 1. 1. 1. 1. 1.]
score: 77.78%

CV Fold 4/5
TRAIN/VAL: 36 [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 17, 18, 21, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43]
TEST: 8 [2, 13, 16, 19, 20, 28, 30, 35]
Bootstrap Sample Set:
Tiny   | train: (108, 14000, 20) test: (8, 14000, 20)
Small  | train: (108, 14000, 20) test: (8, 14000, 20)
Medium | train: (108, 14000, 20) test: (8, 14000, 20)
Large  | train: (108, 14000, 20) test: (8, 14000, 20)
Huge   | train: (108, 14000, 20) test: (8, 14000, 20)
Tiny Model 2 units
X_train: (75, 14000, 20)
Train on 75 samples, validate on 33 samples
Epoch 1/20
 - 20s - loss: 0.6420 - acc: 0.7200 - val_loss: 0.6408 - val_acc: 0.7273
Epoch 2/20
 - 14s - loss: 0.6392 - acc: 0.7200 - val_loss: 0.6394 - val_acc: 0.7273
Epoch 3/20
 - 14s - loss: 0.6400 - acc: 0.7200 - val_loss: 0.6380 - val_acc: 0.7273
Epoch 4/20
 - 14s - loss: 0.6445 - acc: 0.7200 - val_loss: 0.6365 - val_acc: 0.7273
Epoch 5/20
 - 14s - loss: 0.6396 - acc: 0.7200 - val_loss: 0.6349 - val_acc: 0.7273
Epoch 6/20
 - 14s - loss: 0.6356 - acc: 0.7200 - val_loss: 0.6333 - val_acc: 0.7273
Epoch 7/20
 - 13s - loss: 0.6333 - acc: 0.7200 - val_loss: 0.6316 - val_acc: 0.7273
Epoch 8/20
 - 14s - loss: 0.6344 - acc: 0.7200 - val_loss: 0.6300 - val_acc: 0.7273
Epoch 9/20
 - 14s - loss: 0.6378 - acc: 0.7200 - val_loss: 0.6283 - val_acc: 0.7273
Epoch 10/20
 - 14s - loss: 0.6331 - acc: 0.7200 - val_loss: 0.6267 - val_acc: 0.7273
Epoch 11/20
 - 14s - loss: 0.6279 - acc: 0.7200 - val_loss: 0.6250 - val_acc: 0.7273
Epoch 12/20
 - 14s - loss: 0.6242 - acc: 0.7200 - val_loss: 0.6234 - val_acc: 0.7273
Epoch 13/20
 - 14s - loss: 0.6237 - acc: 0.7200 - val_loss: 0.6218 - val_acc: 0.7273
Epoch 14/20
 - 14s - loss: 0.6233 - acc: 0.7200 - val_loss: 0.6201 - val_acc: 0.7273
Epoch 15/20
 - 14s - loss: 0.6251 - acc: 0.7200 - val_loss: 0.6186 - val_acc: 0.7273
Epoch 16/20
 - 14s - loss: 0.6218 - acc: 0.7200 - val_loss: 0.6170 - val_acc: 0.7273
Epoch 17/20
 - 14s - loss: 0.6171 - acc: 0.7200 - val_loss: 0.6156 - val_acc: 0.7273
Epoch 18/20
 - 14s - loss: 0.6117 - acc: 0.7200 - val_loss: 0.6141 - val_acc: 0.7273
Epoch 19/20
 - 14s - loss: 0.6158 - acc: 0.7200 - val_loss: 0.6128 - val_acc: 0.7273
Epoch 20/20
 - 14s - loss: 0.6168 - acc: 0.7200 - val_loss: 0.6115 - val_acc: 0.7273
Small Model 10 units
X_train: (75, 14000, 20)
Train on 75 samples, validate on 33 samples
Epoch 1/20
 - 19s - loss: 0.6207 - acc: 0.6667 - val_loss: 0.6703 - val_acc: 0.6061
Epoch 2/20
 - 13s - loss: 0.6291 - acc: 0.6800 - val_loss: 0.6662 - val_acc: 0.6061
Epoch 3/20
 - 14s - loss: 0.6107 - acc: 0.7067 - val_loss: 0.6624 - val_acc: 0.6061
Epoch 4/20
 - 14s - loss: 0.6113 - acc: 0.7200 - val_loss: 0.6589 - val_acc: 0.6667
Epoch 5/20
 - 13s - loss: 0.5939 - acc: 0.7867 - val_loss: 0.6557 - val_acc: 0.6970
Epoch 6/20
 - 13s - loss: 0.5924 - acc: 0.6933 - val_loss: 0.6529 - val_acc: 0.6667
Epoch 7/20
 - 13s - loss: 0.5894 - acc: 0.7733 - val_loss: 0.6505 - val_acc: 0.6667
Epoch 8/20
 - 14s - loss: 0.5719 - acc: 0.7733 - val_loss: 0.6486 - val_acc: 0.6667
Epoch 9/20
 - 14s - loss: 0.5804 - acc: 0.7467 - val_loss: 0.6473 - val_acc: 0.6667
Epoch 10/20
 - 13s - loss: 0.5675 - acc: 0.7467 - val_loss: 0.6467 - val_acc: 0.6667
Epoch 11/20
 - 14s - loss: 0.5811 - acc: 0.7333 - val_loss: 0.6467 - val_acc: 0.6667
Epoch 12/20
 - 14s - loss: 0.5601 - acc: 0.7467 - val_loss: 0.6474 - val_acc: 0.6667
Epoch 13/20
 - 13s - loss: 0.5669 - acc: 0.7600 - val_loss: 0.6484 - val_acc: 0.6667
Epoch 14/20
 - 15s - loss: 0.5701 - acc: 0.7467 - val_loss: 0.6498 - val_acc: 0.6667
Epoch 15/20
 - 14s - loss: 0.5641 - acc: 0.7467 - val_loss: 0.6513 - val_acc: 0.6667
Epoch 16/20
 - 13s - loss: 0.5449 - acc: 0.7467 - val_loss: 0.6529 - val_acc: 0.6667
Epoch 17/20
 - 14s - loss: 0.5656 - acc: 0.7467 - val_loss: 0.6546 - val_acc: 0.6667
Epoch 18/20
 - 14s - loss: 0.5615 - acc: 0.7467 - val_loss: 0.6562 - val_acc: 0.6667
Epoch 19/20
 - 13s - loss: 0.5526 - acc: 0.7467 - val_loss: 0.6577 - val_acc: 0.6667
Epoch 20/20
 - 14s - loss: 0.5436 - acc: 0.7467 - val_loss: 0.6592 - val_acc: 0.6667
Medium Model 25 units
X_train: (75, 14000, 20)
Train on 75 samples, validate on 33 samples
Epoch 1/20
 - 19s - loss: 0.6975 - acc: 0.4533 - val_loss: 0.6859 - val_acc: 0.6061
Epoch 2/20
 - 13s - loss: 0.6936 - acc: 0.5733 - val_loss: 0.6783 - val_acc: 0.6667
Epoch 3/20
 - 13s - loss: 0.6719 - acc: 0.6667 - val_loss: 0.6713 - val_acc: 0.6667
Epoch 4/20
 - 13s - loss: 0.6610 - acc: 0.6933 - val_loss: 0.6659 - val_acc: 0.6667
Epoch 5/20
 - 14s - loss: 0.6555 - acc: 0.7333 - val_loss: 0.6617 - val_acc: 0.6667
Epoch 6/20
 - 15s - loss: 0.6421 - acc: 0.7067 - val_loss: 0.6585 - val_acc: 0.6667
Epoch 7/20
 - 14s - loss: 0.6352 - acc: 0.7333 - val_loss: 0.6558 - val_acc: 0.6667
Epoch 8/20
 - 14s - loss: 0.6355 - acc: 0.7467 - val_loss: 0.6537 - val_acc: 0.6667
Epoch 9/20
 - 14s - loss: 0.6300 - acc: 0.7333 - val_loss: 0.6520 - val_acc: 0.6667
Epoch 10/20
 - 16s - loss: 0.6251 - acc: 0.7467 - val_loss: 0.6506 - val_acc: 0.6667
Epoch 11/20
 - 14s - loss: 0.6195 - acc: 0.7467 - val_loss: 0.6494 - val_acc: 0.6667
Epoch 12/20
 - 13s - loss: 0.6171 - acc: 0.7467 - val_loss: 0.6483 - val_acc: 0.6667
Epoch 13/20
 - 14s - loss: 0.6132 - acc: 0.7467 - val_loss: 0.6474 - val_acc: 0.6667
Epoch 14/20
 - 14s - loss: 0.6056 - acc: 0.7467 - val_loss: 0.6465 - val_acc: 0.6667
Epoch 15/20
 - 14s - loss: 0.6053 - acc: 0.7467 - val_loss: 0.6457 - val_acc: 0.6667
Epoch 16/20
 - 14s - loss: 0.6064 - acc: 0.7467 - val_loss: 0.6449 - val_acc: 0.6667
Epoch 17/20
 - 15s - loss: 0.6046 - acc: 0.7467 - val_loss: 0.6442 - val_acc: 0.6667
Epoch 18/20
 - 14s - loss: 0.6030 - acc: 0.7467 - val_loss: 0.6435 - val_acc: 0.6667
Epoch 19/20
 - 14s - loss: 0.5999 - acc: 0.7467 - val_loss: 0.6429 - val_acc: 0.6667
Epoch 20/20
 - 14s - loss: 0.6007 - acc: 0.7467 - val_loss: 0.6423 - val_acc: 0.6667
Large Model 50 units
X_train: (75, 14000, 20)
Train on 75 samples, validate on 33 samples
Epoch 1/20
 - 22s - loss: 0.6526 - acc: 0.7200 - val_loss: 0.6136 - val_acc: 0.7576
Epoch 2/20
 - 14s - loss: 0.6384 - acc: 0.7067 - val_loss: 0.6027 - val_acc: 0.7576
Epoch 3/20
 - 16s - loss: 0.6331 - acc: 0.7067 - val_loss: 0.5947 - val_acc: 0.7576
Epoch 4/20
 - 14s - loss: 0.6214 - acc: 0.7067 - val_loss: 0.5894 - val_acc: 0.7576
Epoch 5/20
 - 14s - loss: 0.6185 - acc: 0.7067 - val_loss: 0.5855 - val_acc: 0.7576
Epoch 6/20
 - 14s - loss: 0.6170 - acc: 0.7067 - val_loss: 0.5822 - val_acc: 0.7576
Epoch 7/20
 - 14s - loss: 0.6114 - acc: 0.7067 - val_loss: 0.5794 - val_acc: 0.7576
Epoch 8/20
 - 14s - loss: 0.6105 - acc: 0.7067 - val_loss: 0.5769 - val_acc: 0.7576
Epoch 9/20
 - 14s - loss: 0.6097 - acc: 0.7067 - val_loss: 0.5746 - val_acc: 0.7576
Epoch 10/20
 - 14s - loss: 0.6097 - acc: 0.7067 - val_loss: 0.5726 - val_acc: 0.7576
Epoch 11/20
 - 14s - loss: 0.6079 - acc: 0.7067 - val_loss: 0.5708 - val_acc: 0.7576
Epoch 12/20
 - 15s - loss: 0.6067 - acc: 0.7067 - val_loss: 0.5692 - val_acc: 0.7576
Epoch 13/20
 - 15s - loss: 0.6064 - acc: 0.7067 - val_loss: 0.5677 - val_acc: 0.7576
Epoch 14/20
 - 15s - loss: 0.6053 - acc: 0.7067 - val_loss: 0.5664 - val_acc: 0.7576
Epoch 15/20
 - 15s - loss: 0.6054 - acc: 0.7067 - val_loss: 0.5652 - val_acc: 0.7576
Epoch 16/20
 - 14s - loss: 0.6037 - acc: 0.7067 - val_loss: 0.5642 - val_acc: 0.7576
Epoch 17/20
 - 15s - loss: 0.6050 - acc: 0.7067 - val_loss: 0.5634 - val_acc: 0.7576
Epoch 18/20
 - 15s - loss: 0.6046 - acc: 0.7067 - val_loss: 0.5626 - val_acc: 0.7576
Epoch 19/20
 - 15s - loss: 0.6064 - acc: 0.7067 - val_loss: 0.5619 - val_acc: 0.7576
Epoch 20/20
 - 15s - loss: 0.6058 - acc: 0.7067 - val_loss: 0.5614 - val_acc: 0.7576
Huge Model 100 units
X_train: (75, 14000, 20)
Train on 75 samples, validate on 33 samples
Epoch 1/20
 - 51s - loss: 0.6517 - acc: 0.7067 - val_loss: 0.6360 - val_acc: 0.6970
Epoch 2/20
 - 18s - loss: 0.6328 - acc: 0.7333 - val_loss: 0.6221 - val_acc: 0.6970
Epoch 3/20
 - 18s - loss: 0.6088 - acc: 0.7333 - val_loss: 0.6168 - val_acc: 0.6970
Epoch 4/20
 - 18s - loss: 0.5943 - acc: 0.7333 - val_loss: 0.6151 - val_acc: 0.6970
Epoch 5/20
 - 18s - loss: 0.5863 - acc: 0.7333 - val_loss: 0.6146 - val_acc: 0.6970
Epoch 6/20
 - 18s - loss: 0.5866 - acc: 0.7333 - val_loss: 0.6146 - val_acc: 0.6970
Epoch 7/20
 - 18s - loss: 0.5828 - acc: 0.7333 - val_loss: 0.6148 - val_acc: 0.6970
Epoch 8/20
 - 18s - loss: 0.5822 - acc: 0.7333 - val_loss: 0.6154 - val_acc: 0.6970
Epoch 9/20
 - 18s - loss: 0.5790 - acc: 0.7333 - val_loss: 0.6161 - val_acc: 0.6970
Epoch 10/20
 - 18s - loss: 0.5786 - acc: 0.7333 - val_loss: 0.6171 - val_acc: 0.6970
Epoch 11/20
 - 18s - loss: 0.5775 - acc: 0.7333 - val_loss: 0.6183 - val_acc: 0.6970
Epoch 12/20
 - 19s - loss: 0.5773 - acc: 0.7333 - val_loss: 0.6197 - val_acc: 0.6970
Epoch 13/20
 - 18s - loss: 0.5750 - acc: 0.7333 - val_loss: 0.6213 - val_acc: 0.6970
Epoch 14/20
 - 18s - loss: 0.5746 - acc: 0.7333 - val_loss: 0.6229 - val_acc: 0.6970
Epoch 15/20
 - 18s - loss: 0.5759 - acc: 0.7333 - val_loss: 0.6244 - val_acc: 0.6970
Epoch 16/20
 - 18s - loss: 0.5749 - acc: 0.7333 - val_loss: 0.6257 - val_acc: 0.6970
Epoch 17/20
 - 17s - loss: 0.5712 - acc: 0.7333 - val_loss: 0.6269 - val_acc: 0.6970
Epoch 18/20
 - 17s - loss: 0.5708 - acc: 0.7333 - val_loss: 0.6278 - val_acc: 0.6970
Epoch 19/20
 - 16s - loss: 0.5700 - acc: 0.7333 - val_loss: 0.6288 - val_acc: 0.6970
Epoch 20/20
 - 17s - loss: 0.5680 - acc: 0.7333 - val_loss: 0.6298 - val_acc: 0.6970
y_test:      [1 0 0 1 1 1 1 1]
Tiny   pred: [[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]]
Small  pred: [[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]]
Medium pred: [[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]]
Large  pred: [[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]]
Huge   pred: [[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]]
final_pred:  [1. 1. 1. 1. 1. 1. 1. 1.]
score: 75.00%

CV Fold 5/5
TRAIN/VAL: 36 [0, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 36, 37, 40, 41, 43]
TEST: 8 [1, 8, 12, 32, 34, 38, 39, 42]
Bootstrap Sample Set:
Tiny   | train: (108, 14000, 20) test: (8, 14000, 20)
Small  | train: (108, 14000, 20) test: (8, 14000, 20)
Medium | train: (108, 14000, 20) test: (8, 14000, 20)
Large  | train: (108, 14000, 20) test: (8, 14000, 20)
Huge   | train: (108, 14000, 20) test: (8, 14000, 20)
Tiny Model 2 units
X_train: (75, 14000, 20)
Train on 75 samples, validate on 33 samples
Epoch 1/20
 - 23s - loss: 0.6533 - acc: 0.7467 - val_loss: 0.6645 - val_acc: 0.6970
Epoch 2/20
 - 14s - loss: 0.6503 - acc: 0.7733 - val_loss: 0.6628 - val_acc: 0.6970
Epoch 3/20
 - 14s - loss: 0.6456 - acc: 0.7333 - val_loss: 0.6614 - val_acc: 0.6970
Epoch 4/20
 - 14s - loss: 0.6406 - acc: 0.7600 - val_loss: 0.6599 - val_acc: 0.6970
Epoch 5/20
 - 13s - loss: 0.6400 - acc: 0.7333 - val_loss: 0.6584 - val_acc: 0.6970
Epoch 6/20
 - 14s - loss: 0.6459 - acc: 0.7333 - val_loss: 0.6570 - val_acc: 0.6970
Epoch 7/20
 - 13s - loss: 0.6389 - acc: 0.7467 - val_loss: 0.6555 - val_acc: 0.6970
Epoch 8/20
 - 13s - loss: 0.6407 - acc: 0.7333 - val_loss: 0.6541 - val_acc: 0.6970
Epoch 9/20
 - 13s - loss: 0.6403 - acc: 0.7333 - val_loss: 0.6527 - val_acc: 0.6970
Epoch 10/20
 - 14s - loss: 0.6358 - acc: 0.7467 - val_loss: 0.6514 - val_acc: 0.6970
Epoch 11/20
 - 14s - loss: 0.6361 - acc: 0.7333 - val_loss: 0.6501 - val_acc: 0.6970
Epoch 12/20
 - 13s - loss: 0.6356 - acc: 0.7467 - val_loss: 0.6488 - val_acc: 0.6970
Epoch 13/20
 - 13s - loss: 0.6348 - acc: 0.7467 - val_loss: 0.6475 - val_acc: 0.6970
Epoch 14/20
 - 14s - loss: 0.6363 - acc: 0.7333 - val_loss: 0.6463 - val_acc: 0.6970
Epoch 15/20
 - 15s - loss: 0.6259 - acc: 0.7467 - val_loss: 0.6451 - val_acc: 0.6970
Epoch 16/20
 - 14s - loss: 0.6280 - acc: 0.7467 - val_loss: 0.6440 - val_acc: 0.6970
Epoch 17/20
 - 14s - loss: 0.6245 - acc: 0.7467 - val_loss: 0.6428 - val_acc: 0.6970
Epoch 18/20
 - 14s - loss: 0.6191 - acc: 0.7467 - val_loss: 0.6417 - val_acc: 0.6970
Epoch 19/20
 - 13s - loss: 0.6177 - acc: 0.7467 - val_loss: 0.6407 - val_acc: 0.6970
Epoch 20/20
 - 14s - loss: 0.6249 - acc: 0.7467 - val_loss: 0.6396 - val_acc: 0.6970
Small Model 10 units
X_train: (75, 14000, 20)
Train on 75 samples, validate on 33 samples
Epoch 1/20
 - 22s - loss: 0.6494 - acc: 0.6267 - val_loss: 0.6269 - val_acc: 0.7879
Epoch 2/20
 - 14s - loss: 0.6385 - acc: 0.6400 - val_loss: 0.5959 - val_acc: 0.8182
Epoch 3/20
 - 14s - loss: 0.6271 - acc: 0.6933 - val_loss: 0.5739 - val_acc: 0.8182
Epoch 4/20
 - 13s - loss: 0.6128 - acc: 0.6800 - val_loss: 0.5568 - val_acc: 0.8182
Epoch 5/20
 - 13s - loss: 0.6090 - acc: 0.7733 - val_loss: 0.5431 - val_acc: 0.7879
Epoch 6/20
 - 14s - loss: 0.5930 - acc: 0.7867 - val_loss: 0.5322 - val_acc: 0.7879
Epoch 7/20
 - 14s - loss: 0.5873 - acc: 0.7733 - val_loss: 0.5236 - val_acc: 0.8182
Epoch 8/20
 - 14s - loss: 0.5662 - acc: 0.7867 - val_loss: 0.5166 - val_acc: 0.9091
Epoch 9/20
 - 13s - loss: 0.5744 - acc: 0.8133 - val_loss: 0.5108 - val_acc: 0.9091
Epoch 10/20
 - 13s - loss: 0.5751 - acc: 0.7733 - val_loss: 0.5059 - val_acc: 0.9091
Epoch 11/20
 - 14s - loss: 0.5789 - acc: 0.7867 - val_loss: 0.5017 - val_acc: 0.9091
Epoch 12/20
 - 14s - loss: 0.5739 - acc: 0.7733 - val_loss: 0.4980 - val_acc: 0.9394
Epoch 13/20
 - 14s - loss: 0.5565 - acc: 0.8133 - val_loss: 0.4947 - val_acc: 0.9091
Epoch 14/20
 - 14s - loss: 0.5548 - acc: 0.8000 - val_loss: 0.4917 - val_acc: 0.9091
Epoch 15/20
 - 13s - loss: 0.5630 - acc: 0.7600 - val_loss: 0.4890 - val_acc: 0.9091
Epoch 16/20
 - 14s - loss: 0.5702 - acc: 0.7333 - val_loss: 0.4864 - val_acc: 0.9091
Epoch 17/20
 - 13s - loss: 0.5420 - acc: 0.8133 - val_loss: 0.4839 - val_acc: 0.9091
Epoch 18/20
 - 14s - loss: 0.5320 - acc: 0.8533 - val_loss: 0.4815 - val_acc: 0.9091
Epoch 19/20
 - 13s - loss: 0.5289 - acc: 0.8000 - val_loss: 0.4792 - val_acc: 0.9091
Epoch 20/20
 - 14s - loss: 0.5521 - acc: 0.8133 - val_loss: 0.4770 - val_acc: 0.9091
Medium Model 25 units
X_train: (75, 14000, 20)
Train on 75 samples, validate on 33 samples
Epoch 1/20
 - 23s - loss: 0.8338 - acc: 0.2933 - val_loss: 0.8490 - val_acc: 0.2121
Epoch 2/20
 - 14s - loss: 0.8095 - acc: 0.2933 - val_loss: 0.8151 - val_acc: 0.2121
Epoch 3/20
 - 14s - loss: 0.8116 - acc: 0.2800 - val_loss: 0.7791 - val_acc: 0.2121
Epoch 4/20
 - 14s - loss: 0.7671 - acc: 0.3067 - val_loss: 0.7361 - val_acc: 0.3030
Epoch 5/20
 - 14s - loss: 0.7399 - acc: 0.3733 - val_loss: 0.7000 - val_acc: 0.5152
Epoch 6/20
 - 14s - loss: 0.7191 - acc: 0.4400 - val_loss: 0.6728 - val_acc: 0.6667
Epoch 7/20
 - 13s - loss: 0.6859 - acc: 0.6400 - val_loss: 0.6519 - val_acc: 0.7273
Epoch 8/20
 - 14s - loss: 0.6665 - acc: 0.6533 - val_loss: 0.6354 - val_acc: 0.7273
Epoch 9/20
 - 14s - loss: 0.6558 - acc: 0.6800 - val_loss: 0.6219 - val_acc: 0.7273
Epoch 10/20
 - 14s - loss: 0.6411 - acc: 0.6800 - val_loss: 0.6114 - val_acc: 0.7879
Epoch 11/20
 - 15s - loss: 0.6412 - acc: 0.7067 - val_loss: 0.6034 - val_acc: 0.7879
Epoch 12/20
 - 14s - loss: 0.6263 - acc: 0.7200 - val_loss: 0.5970 - val_acc: 0.7879
Epoch 13/20
 - 14s - loss: 0.6155 - acc: 0.7200 - val_loss: 0.5919 - val_acc: 0.7879
Epoch 14/20
 - 13s - loss: 0.6085 - acc: 0.7200 - val_loss: 0.5874 - val_acc: 0.7879
Epoch 15/20
 - 13s - loss: 0.6121 - acc: 0.7200 - val_loss: 0.5834 - val_acc: 0.7879
Epoch 16/20
 - 13s - loss: 0.6053 - acc: 0.7333 - val_loss: 0.5797 - val_acc: 0.7879
Epoch 17/20
 - 13s - loss: 0.5982 - acc: 0.7600 - val_loss: 0.5762 - val_acc: 0.7273
Epoch 18/20
 - 13s - loss: 0.5903 - acc: 0.7600 - val_loss: 0.5728 - val_acc: 0.7576
Epoch 19/20
 - 14s - loss: 0.5898 - acc: 0.7333 - val_loss: 0.5693 - val_acc: 0.7273
Epoch 20/20
 - 14s - loss: 0.5986 - acc: 0.7467 - val_loss: 0.5657 - val_acc: 0.8182
Large Model 50 units
X_train: (75, 14000, 20)
Train on 75 samples, validate on 33 samples
Epoch 1/20
 - 25s - loss: 0.7121 - acc: 0.2933 - val_loss: 0.6938 - val_acc: 0.3333
Epoch 2/20
 - 15s - loss: 0.7017 - acc: 0.3733 - val_loss: 0.6767 - val_acc: 0.7273
Epoch 3/20
 - 14s - loss: 0.6813 - acc: 0.6267 - val_loss: 0.6590 - val_acc: 0.7879
Epoch 4/20
 - 16s - loss: 0.6669 - acc: 0.6933 - val_loss: 0.6443 - val_acc: 0.7879
Epoch 5/20
 - 14s - loss: 0.6552 - acc: 0.7067 - val_loss: 0.6312 - val_acc: 0.7879
Epoch 6/20
 - 14s - loss: 0.6468 - acc: 0.7067 - val_loss: 0.6194 - val_acc: 0.7879
Epoch 7/20
 - 14s - loss: 0.6393 - acc: 0.7067 - val_loss: 0.6088 - val_acc: 0.7879
Epoch 8/20
 - 14s - loss: 0.6307 - acc: 0.7067 - val_loss: 0.5997 - val_acc: 0.7879
Epoch 9/20
 - 14s - loss: 0.6244 - acc: 0.7067 - val_loss: 0.5919 - val_acc: 0.7879
Epoch 10/20
 - 14s - loss: 0.6208 - acc: 0.7067 - val_loss: 0.5851 - val_acc: 0.7879
Epoch 11/20
 - 14s - loss: 0.6204 - acc: 0.7067 - val_loss: 0.5794 - val_acc: 0.7879
Epoch 12/20
 - 14s - loss: 0.6159 - acc: 0.7067 - val_loss: 0.5742 - val_acc: 0.7879
Epoch 13/20
 - 14s - loss: 0.6104 - acc: 0.7067 - val_loss: 0.5694 - val_acc: 0.7879
Epoch 14/20
 - 14s - loss: 0.6078 - acc: 0.7067 - val_loss: 0.5647 - val_acc: 0.7879
Epoch 15/20
 - 14s - loss: 0.6087 - acc: 0.7067 - val_loss: 0.5601 - val_acc: 0.7879
Epoch 16/20
 - 14s - loss: 0.6045 - acc: 0.7067 - val_loss: 0.5555 - val_acc: 0.7879
Epoch 17/20
 - 15s - loss: 0.5972 - acc: 0.7067 - val_loss: 0.5509 - val_acc: 0.7879
Epoch 18/20
 - 14s - loss: 0.5940 - acc: 0.7067 - val_loss: 0.5464 - val_acc: 0.7879
Epoch 19/20
 - 14s - loss: 0.5893 - acc: 0.7067 - val_loss: 0.5422 - val_acc: 0.7879
Epoch 20/20
 - 14s - loss: 0.5862 - acc: 0.7067 - val_loss: 0.5384 - val_acc: 0.7879
Huge Model 100 units
X_train: (75, 14000, 20)
Train on 75 samples, validate on 33 samples
Epoch 1/20
 - 91s - loss: 0.6679 - acc: 0.7067 - val_loss: 0.6488 - val_acc: 0.6364
Epoch 2/20
 - 18s - loss: 0.6209 - acc: 0.7867 - val_loss: 0.6481 - val_acc: 0.6364
Epoch 3/20
 - 17s - loss: 0.5997 - acc: 0.7733 - val_loss: 0.6493 - val_acc: 0.6364
Epoch 4/20
 - 17s - loss: 0.5963 - acc: 0.7733 - val_loss: 0.6498 - val_acc: 0.6364
Epoch 5/20
 - 16s - loss: 0.5878 - acc: 0.7733 - val_loss: 0.6493 - val_acc: 0.6364
Epoch 6/20
 - 16s - loss: 0.5786 - acc: 0.7733 - val_loss: 0.6479 - val_acc: 0.6364
Epoch 7/20
 - 16s - loss: 0.5775 - acc: 0.7733 - val_loss: 0.6463 - val_acc: 0.6364
Epoch 8/20
 - 16s - loss: 0.5716 - acc: 0.7733 - val_loss: 0.6442 - val_acc: 0.6364
Epoch 9/20
 - 17s - loss: 0.5633 - acc: 0.7733 - val_loss: 0.6410 - val_acc: 0.6364
Epoch 10/20
 - 16s - loss: 0.5540 - acc: 0.7733 - val_loss: 0.6360 - val_acc: 0.6364
Epoch 11/20
 - 16s - loss: 0.5494 - acc: 0.7733 - val_loss: 0.6287 - val_acc: 0.6364
Epoch 12/20
 - 16s - loss: 0.5364 - acc: 0.7733 - val_loss: 0.6169 - val_acc: 0.6364
Epoch 13/20
 - 17s - loss: 0.5355 - acc: 0.7733 - val_loss: 0.6002 - val_acc: 0.6364
Epoch 14/20
 - 18s - loss: 0.5253 - acc: 0.7733 - val_loss: 0.5815 - val_acc: 0.6364
Epoch 15/20
 - 18s - loss: 0.5104 - acc: 0.7733 - val_loss: 0.5641 - val_acc: 0.6364
Epoch 16/20
 - 17s - loss: 0.4989 - acc: 0.7733 - val_loss: 0.5496 - val_acc: 0.7879
Epoch 17/20
 - 17s - loss: 0.4915 - acc: 0.8267 - val_loss: 0.5391 - val_acc: 0.7273
Epoch 18/20
 - 17s - loss: 0.4839 - acc: 0.8267 - val_loss: 0.5312 - val_acc: 0.7273
Epoch 19/20
 - 16s - loss: 0.4738 - acc: 0.8000 - val_loss: 0.5241 - val_acc: 0.7576
Epoch 20/20
 - 18s - loss: 0.4665 - acc: 0.8133 - val_loss: 0.5164 - val_acc: 0.8485
y_test:      [1 0 0 1 1 1 1 1]
Tiny   pred: [[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]]
Small  pred: [[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]]
Medium pred: [[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]]
Large  pred: [[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]]
Huge   pred: [[ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [ True]
 [False]
 [ True]]
final_pred:  [1. 1. 1. 1. 1. 1. 1. 1.]
score: 75.00%

Cross Fold Classification Accuracy:
75.11% (+/- 2.84%)
Confusion matrix, without normalization
[[ 0 11]
 [ 0 33]]
Elapsed Time: 02:07:00.88

Process finished with exit code 0
